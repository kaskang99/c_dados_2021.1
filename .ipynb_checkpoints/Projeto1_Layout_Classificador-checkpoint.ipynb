{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Lucas Franco Florentino\n",
    "\n",
    "Nome: Lucas Kang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo kit kat.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "filename = 'kit kat.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@biaturci bia tmb √© did√°tica!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 kit kat por 10 pila na americanas, vou logo ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e se eu trocar meu nick pra: kit kat...\\nalgue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@pivetabeca o pre√ßo q eh uma barra de kit kat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qria um ovo d chocolate da alpino ou da kit ka...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  class\n",
       "0                    @biaturci bia tmb √© did√°tica!!!      0\n",
       "1  6 kit kat por 10 pila na americanas, vou logo ...      2\n",
       "2  e se eu trocar meu nick pra: kit kat...\\nalgue...      0\n",
       "3  @pivetabeca o pre√ßo q eh uma barra de kit kat ...      1\n",
       "4  qria um ovo d chocolate da alpino ou da kit ka...      4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>class</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queria dar de presente pra minha irm√£ o kit ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@123luigig @lilyandgia kit kat √© mt bom</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tudo que eu precisava neste exato momento era:...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kit kat eu te amo esse tu√≠te √© pra vc</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  class  Unnamed: 2  \\\n",
       "0  queria dar de presente pra minha irm√£ o kit ka...      1         NaN   \n",
       "1            @123luigig @lilyandgia kit kat √© mt bom      4         NaN   \n",
       "2  kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§      4         NaN   \n",
       "3  tudo que eu precisava neste exato momento era:...      4         NaN   \n",
       "4              kit kat eu te amo esse tu√≠te √© pra vc      4         NaN   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \n",
       "0         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a classifica√ß√£o foi usada 5 tipos, Muito relevante, Relevante, Neutro, Irrelevantee Muito irrelevante. A classifica√ß√£o foi baseada no n√≠vel de rela√ß√£o que o tweet tinha com nosso produto. Portanto, um tweet Muito relevante ou Relevante, deveria apresentar uma opni√£o explicita sobre o produto seja ela positiva ou negativa. Um tweet Neutro, seria aquele que somente cita o nome do produto. E para finalizar um Muito irrelevante ou Irrelevante deveria n√£o citar o nome do produto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Para iniciar a progama√ß√£o do classificador, foi necess√°rio limpar os dados para eliminar poss√≠veis distratores no processo de classifica√ß√£o. Desse modo, a fun√ß√£o 'cleanup' junto com a biblioteca nltk, realizaram a limpeza da base de dados.\n",
    "Ap√≥s a limpeza, os dados s√£o separados em listas e feita a contagem das frequencias absolutas e relativas de cada lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Faz a limpeza da base de dados e retira stop words\n",
    "import re \n",
    "def cleanup(text):\n",
    "    punctuation = '[/\\@!-.:?;\\n\"\"‚Äú‚Äù,_]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    texto_limpo= re.sub(pattern, '', text)\n",
    "    return  texto_limpo\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('portuguese')\n",
    "stop_list = [\"de\", \"√©\", \"√°\", \"√†\", \"ao\", \"a\", \"o\", \"√©\", \"rt\", '\"', \"‚Äú\", \"'\", \",\", \"(\", \")\", \"$\", \"%\", \"*\", \"&\", \"+\", \"=\"]\n",
    "stop.extend(stop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define as classifica√ß√µes como categorias\n",
    "\n",
    "train = pd.read_excel(filename)\n",
    "treino_mrel = train.loc[train['class'] == 4,:]\n",
    "treino_rel = train.loc[train['class'] == 3,:]\n",
    "treino_neut = train.loc[train['class'] == 2,:]\n",
    "treino_irrel = train.loc[train['class'] == 1,:]\n",
    "treino_mirrel = train.loc[train['class'] == 0,:]\n",
    "\n",
    "teste_mrel= test.loc[train['class'] == 4,:]\n",
    "teste_rel = test.loc[train['class'] == 3,:]\n",
    "teste_neut = test.loc[train['class'] == 2,:]\n",
    "teste_irrel = test.loc[train['class'] == 1,:]\n",
    "teste_mirrel = test.loc[train['class'] == 0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-90aeb146183d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_mrel['Treinamento'] = treino_mrel['Treinamento'].astype(str)\n",
      "<ipython-input-7-90aeb146183d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_rel['Treinamento'] = treino_rel['Treinamento'].astype(str)\n",
      "<ipython-input-7-90aeb146183d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_neut['Treinamento'] = treino_neut['Treinamento'].astype(str)\n",
      "<ipython-input-7-90aeb146183d>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_irrel['Treinamento'] = treino_irrel['Treinamento'].astype(str)\n",
      "<ipython-input-7-90aeb146183d>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_mirrel['Treinamento'] = treino_mirrel['Treinamento'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "#Separando a base dados para Muito relevante, Relevante, Neutro, Irrelevante, Muito irrelevante\n",
    "treino_mrel['Treinamento'] = treino_mrel['Treinamento'].astype(str)\n",
    "treino_rel['Treinamento'] = treino_rel['Treinamento'].astype(str)\n",
    "treino_neut['Treinamento'] = treino_neut['Treinamento'].astype(str)\n",
    "treino_irrel['Treinamento'] = treino_irrel['Treinamento'].astype(str)\n",
    "treino_mirrel['Treinamento'] = treino_mirrel['Treinamento'].astype(str)\n",
    " \n",
    "#Coloca tudo em uma lista\n",
    "lista_tr_mrel= treino_mrel['Treinamento'].tolist()\n",
    "lista_tr_rel= treino_rel['Treinamento'].tolist()\n",
    "lista_tr_neut= treino_neut['Treinamento'].tolist()\n",
    "lista_tr_irrel= treino_irrel['Treinamento'].tolist()\n",
    "lista_tr_mirrel= treino_mirrel['Treinamento'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fun√ß√£o para aplicar a limpeza nos dados de treinamento para:\n",
    "\n",
    "#Muito Relevante\n",
    "tr_mrel_limpo = []\n",
    "for txt in lista_tr_mrel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_mrel_limpo.append(txt)\n",
    "tr_mrel_limpo =[' '.join([w for w in x.lower().split() if w not in stop]) #Aplica a fun√ß√£o que retira stop words\n",
    "    for x in tr_mrel_limpo]\n",
    "    \n",
    "tr_mrel_div = []\n",
    "for txt in tr_mrel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_mrel_div.append(txt)\n",
    "\n",
    "    \n",
    "#Relevante\n",
    "\n",
    "tr_rel_limpo = []\n",
    "for txt in lista_tr_rel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_rel_limpo.append(txt)\n",
    "tr_rel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_rel_limpo]\n",
    "    \n",
    "tr_rel_div = []\n",
    "for txt in tr_rel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_rel_div.append(txt)\n",
    "\n",
    "    \n",
    "# Neutro\n",
    "\n",
    "tr_neut_limpo = []\n",
    "for txt in lista_tr_neut:\n",
    "    txt = cleanup(txt)\n",
    "    tr_neut_limpo.append(txt)\n",
    "tr_neut_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_neut_limpo]\n",
    "    \n",
    "tr_neut_div = []\n",
    "for txt in tr_neut_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_neut_div.append(txt)\n",
    "    \n",
    "    \n",
    "#Irrelevante\n",
    "\n",
    "tr_irrel_limpo = []\n",
    "for txt in lista_tr_irrel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_irrel_limpo.append(txt)\n",
    "tr_irrel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_irrel_limpo]\n",
    "    \n",
    "tr_irrel_div = []\n",
    "for txt in tr_irrel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_irrel_div.append(txt)\n",
    "\n",
    "#Muito irrelevante\n",
    "\n",
    "tr_mirrel_limpo = []\n",
    "for txt in lista_tr_mirrel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_mirrel_limpo.append(txt)\n",
    "tr_mirrel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_mirrel_limpo]\n",
    "    \n",
    "tr_mirrel_div = []\n",
    "for txt in tr_mirrel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_mirrel_div.append(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['queria', 'dar', 'presente', 'pra', 'irm√£', 'kit', 'kat', 'parceria', 'now', 'united', '99', 'reais', 'chocolate', 'ü§°', 'cara', 'tentando', 'cancelar', 'compra', 'email', 'ver', 'valor', '135', 'estalecas', 'frete', 'sabendo', 'deixaram', 'claro', 'antes', 'compra', 'httpstcoeverznihri'], ['123luigig', 'lilyandgia', 'kit', 'kat', 'mt', 'bom'], ['kit', 'kat', 'morango', 'lim√£o', 'tudo', 'pra', 'mim', 'ü•∫ü§§'], ['tudo', 'precisava', 'neste', 'exato', 'momento', 'eraum', 'bolo', 'recheio', 'abacaxium', 'bolo', 'churrosum', 'bolo', 'algum', 'chantily', 'gostoso', 'cremoso', 'cima', 'recheio', 'chocolate', 'doce', 'leiteuma', 'torta', 'morangos', 'kit', 'kat', 'qlqr', 'fazia', 'feliz'], ['kit', 'kat', 'amo', 'tu√≠te', 'pra', 'vc'], ['crystaltriste', '3', 'anos', 'info', 'sabe', 'hackear', 'links', 'achar', 'links'], ['liviabarroos', 'fala', 'escuto', 'grito', 'causa', 'kit', 'kat'], ['professora', 'disse', 'ligar', 'camera', 'ganha', 'kit', 'kat', 'httpstcoa2ywkrlzx7'], ['esperei', 'tanto', 'p√°scoa', 'finalmente', 't√°', 'chegando', 'vou', 'ter', 'dinheiro', 'pra', 'comprar', 'kit', 'kat', 'kkkkkkkk'], ['fabymello', 'cheia', 'vontade', 'a√ßa√≠', 'trufado', 'kit', 'kat', 'üò¢'], ['clovestill', 'gente', 'perai', 'httpstcob1aczg6ysh'], ['kitkatoff', 'falsos', 'coltecanos'], ['karolindav', 'fala', 'patroa', 'f√°cil', 'vc', 'dar', 'pode', 'ser', 'kit', 'kat', 'msm', 'p√¥', 'kkkkkk'], ['kit', 'kat', 'horr√≠vel'], ['kitkatoff', 'assim', 'invasivo', 'chamo', 'desconhecidos', 'amor', 'vida', 'nesse', 'site'], ['kit', 'kat', 'httpstcofdoueh24nu'], ['souzzaav', 'aaah', 'vou', 'sim', 't√¥', 'quase', 'indo', 'la', 'comprar', 'kit', 'kat'], ['mesmos', 'criadores', 'pink', 'money', 'vcsdiscordia', 'money', 'httpstcod5kceu24wp'], ['kitkatwbitch', 'ne', 'kit', 'kat'], ['crystaltriste', 'bem', 'ead', 'sei', 'pode', 'invadir', 'links'], ['ainda', 'kit', 'kat', 'ksksksksksksksk'], ['cara', 'compra', 'maconha', 'enqnt', 'podia', 'comprar', 'kit', 'kat', 'kkkkkkkkkkkkkkkk'], ['pensando', 'pago', '80', 'ovo', 'p√°scoa', 'pego', 'dinheiro', 'compro', 'chocolates', 'aleat√≥rios', 'chuva', 'kinder', 'bueno', 'kit', 'kat', 'laka', 'oreo', 'ü§î'], ['mylauram', 't√¥', 'vendo', 'aqui', 'fant√°stico', 'rob√¥s', 'coreia', 'copiando', 'voz', 'artista', 'morto', '20', 'anos', 'pensando', 'quantidade‚Ä¶'], ['avalia√ß√£o', 'aqui', 'comi', 'kit', 'kat', 'gold', 'eh', 'mto', 'ruim', 'parece', 'doce', 'furreba', 'p', 'comer', 'pauzinho', 'so', 'deppis', 'nunca', 'üëçüèª'], ['tristeza', 'cacha√ßa', 'kit', 'kat'], ['queria', 'ganhar', 'm√∫sculo', 'comendo', 'kit', 'kat', 'barras', 'chocolate', 'pedir'], ['le101010', 'aposto', 'dummie', 'dessa', 'prova', 'formou', 'hospedagem', 'cefet'], ['devorkatrina', 'amaryssage', 'kit', 'kat', 'rostinho', 'detonado', 'deixa', 'fazer', 'draminha'], ['queria', 'comer', 'uns', '10', 'kit', 'kat', 'vez'], ['henriquealcini', 't√°', 'sobrevivendo', 'ü§∑üèª\\u200d‚ôÄÔ∏è'], ['markidsp', 'loiolatinha', 'kitkatoff', 'blz', 'mestre'], ['gente', 'responde', 'pffse', 'fizer', 'ovo', 'p√°scoa', 'recheado', 'tp', 'ninho', 'kit', 'kat', 'vcs', 'compram', 'm√£o'], ['caixa', 'kit', 'kat', 'p√°scoa', 'deixaria', 'feliz', 'vida', 'üòç'], ['vontade', 'mt', 'grande', 'comer', 'kit', 'kat', 'kkkkkkk', 'üò≠'], ['nunossauro', 'deres', 'kit', 'kat', 'posso', 'pensar', 'nisso'], ['ovo', 'colher', 'ninho', 'ninho', 'kit', 'kat', 'deliciosas', 'caixinhas', 'bombons', 'recheados', 'sortidos', 'httpstcoy6ub9g5xyx'], ['anivers√°rio', 'guardei', 'kit', 'kat', 'caixinha', 'guarda', 'roupa', 'ai', 'mecher', 'ma', 'caixinha', 'tava', 'la', 'kit', 'kat', 'kkkkkmkkkmmm'], ['ovo', 'p√°scoa', 'kit', 'kat', 'super', 'fininho', 'pequeno', 'comprem', 'deve', 'valer', 'pena', 'pre√ßo', 'pago', 'quero', 'comprar', 'link'], ['pra', 'comer', 'kit', 'kat', 'lambuzar', 'todo'], ['biaturci', 'presidente', 'falou', 'discordar'], ['pai', 'q', 'falou', 'q', 't√°', 'vendo', 'q', 't√¥', 'triste', 'lockdown', 'lembra', 'amava', 'ovo', 'p√°scoa', 'qnd', 'pequena', 'ent', 'comprou', 'kit', 'kat', 'pra', 'mim', 's√©rio', 'q', 'pfto', 'q', 'eh'], ['fiz', 'brigadeiro', 'kit', 'kat', 'ficou', 'mara', 'httpstco9jj5yvqrqo'], ['quer', 'chamar', 'aten√ß√£o', 'compra', 'ovo', 'p√°scoa', 'kit', 'kat', 'p', 'mim'], ['nunca', 'vontade', 'comer', 'doce', 'ai', 'qnd', 'come√ßo', 'treinar', 'd√°', 'vontade', 'comer', 'naked', 'cake', 'c', 'recheio', 'brigadeiro', 'leite', 'ninho', 'milkshake', 'baunilha', 'bobs', 'kinder', 'bueno', 'kit', 'kat', 'aql', 'sorvete', 'hersheys', 'cookiesn', 'cream', 'kibonmeu', 'deus'], ['andreezagomes', 'amooo', 'kit', 'kat', 'kkkkkk'], ['lactabis', 'kit', 'kat', 'ganha', 'lavada', 'bis'], ['mexer', 'mochila', 'achei', 'kit', 'kat', 'fechado', 'tr√™s', 'mil', 'anos', 'atr√°sirei', 'comer', 'd√∫vidas'], ['barbizinea', 'quer', 'chamar', 'aten√ß√£o', 'compra', 'ovo', 'p√°scoa', 'kit', 'kat', 'p', 'mim'], ['jvlaruccia', 'kit', 'kat', 'favorito', 'c'], ['glaucus121', 'invasivo', 'chato', 'talvez'], ['ainda', 'comprou', '6', 'kit', 'kat', 'pra', 'mim', 'ü§©üò¢'], ['matheusamores', 'yanzerass', 'ai', 'liga', 'iphone', 'aparece', 'android', '44', 'kit', 'kat', 'n', 'sabe', 'pq', 'kkkkk'], ['promo√ß√£o', '6', 'kit', 'kat', '10', 'tudo', 'vida', 'queria', 'agora'], ['qr', 'ta√ßa', 'sorvete', 'ovomaltine', 'kit', 'kat', 'chocolate', 'xtudo', 'pizza', 'üò£üò´üò´üò´üò´', 'pedir'], ['ano', 'decidi', 'queria', 'comer', 'ovo', 'p√°scoa', 'caseiro', 'dificuldade', 'achar', 'oreonutellakit', 'kat'], ['marhelo', 'certeza', 'vc', 'casou', 'comigo', 'n√©'], ['kitkats2', 'equitorboquilh', 'felizmente', 'comprometida', 'pra', 'n', 'perder', 'embalo', 'passo', 'pra', 'amiga', 'solteira', 'mengwao', 'üòçüòçüôèüèª'], ['algumas', 'quest√µes', 'aqmds', 'mlk', 'nick', 'merda', 'fodase', 'verme', 'gosteivc', 'n', 'patrickinho', 'apenas', 'queria', 'nick', 'proprio', 'q', 'n', 'nomepq', 'kit', 'kat', 'lol', 'mono', 'katarina', 'amo', 'chocolate', 'acho', 'q', 'ja', 'responde', 'pergunta'], ['ricardopinto20', 'andr√©', 'chamou', 'conto', 'ganza', 'kit', 'kat', 'ahahahahahah'], ['acai', 'nutella', 'morango', 'kit', 'kat', 'erro', 'httpstcorxhjpzp6dk'], ['louieplacex', 'amo', 'tava', 'precisando', 'umas', 'realidades', 'cara', 'sei', 'kit', 'kat'], ['kit', 'kat', 'gold', 'rapaziada', 'comprem', 'ofensa', 'chocolates', 'podre', 'demais'], ['zadoratavares', 'nada', 'melhor', 'receber', 'visita', 'moz√£o', 'trabalho', 'ainda', 'ganhar', 'kit', 'kat', 'nubscampos10', 'menina', 'linda', 'demais‚Ä¶'], ['queria', 'kit', 'kat', 'agora'], ['bfrkarlos', 'ugosantos33', 'rafaela', 'kit', 'kat', 'melhor'], ['vou', 'comer', 'kit', 'kat', 'agora', 'pra', 'fechar', 'noite'], ['descri√ß√£o', 'cesta', 'mini', 'nutella', '140g1', 'barra', 'laka1', 'barra', 'garato', '1', 'caixa', 'ferrero', 'rocher', '100g2', 'pacotes', 'mampm', '45g2', 'barra', 'kit', 'kat2', 'pacote', 'amendoim', 'bibs', '1', 'ovo', '350g', 'ouro', 'branco', '1', 'pacote', 'skittles', '1', 'bebida', 'alpino', '1', 'caixa', 'bis', 'continua'], ['vida', 'mentira', 'pq', 'sempre', 'falei', 'kit', 'vs', 'kat', 'httpstcoqhwd7pmotm'], ['sunsetjoyner', 'sacha', 'httpstcox8uprirmyk'], ['fellipec', 'peguei', 'logo', 'come√ßo', 'pestequando', 'algu√©m', 'fala', 'pegou', 'tomou', 'nada', 'grave', 'digo', 'peguei', 'tomei', '2', 'copos', 'coca', 'cola', '1', 'kit', 'kat', 'dia', 'tb', 'nada', 'grave'], ['uns', '10', 'kit', 'kat', 'alguns', 'finis', 'caixinha', 'bis', 'pra', 'curar', 'tristeza', 'tpmüòû'], ['harrylipstyles', 'compra', 'kit', 'kat', 'barato', 'kinder', 'ovo', 'vc', 'pode', 'comer', 'comum', 'qualquer', '√©poca', 'ano', '2', 'kit', 'kat', 'pre√ßo', '1', 'kinder', 'ovo'], ['caroline', 'sabia', 'sobre', 'vampirismo', 'tanto', 'perguntava', 'qdo', 'viu', 'face', 'assustou', 'logo', 'ali', 'hipnotizada', 'tirar', 'medo', 'assustar', 'face', 'estupro', 'podemos', 'dizer', 'todos', 'estupradores', 'assim', 'kit', 'kat'], ['gusbarcelos', 'sejehomi', 'kitkatbrasil', 'al√¥', 'kitkatbrasil', 'apoie', 'hist√≥ria', 'desse', 'casal', 'lindo', 'ama', 'kit', 'kat', 'namorada', 'amamos', 'vou', 'roubar', 'momento', 'casal'], ['coisas', 'compraria', 'facilmente', 'pasta', 'cremosa', 'kit', 'kat', '21', 'kg'], ['dessa', 'vez', 'fiz', 'rematricula', 'okay'], ['preciso', 'emagrecer', 't√¥', 'gordameu', 'caf√©', 'manh√£', 'hoje', 'doritos', 'kit', 'kat', '√°gua', 'pra', 'dar', 'equilibrada'], ['p√°scoa', 'membros', 'poderiam', 'vestir', 'dan√ßar', 'vers√£o', 'turn', 'it', 'up', 'vestidos', 'coelhos', 'enquanto', 'comiam', 'kit', 'kat', 'partyup'], ['kavmartins', 'josuealm', 't√°', 'gra√ßa', 'sabe', 'gosto', 'kit', 'kat', 'üôÑ', 't√°', 'fazendo', 'porque', 'ultimamente', 'anda', 'rebelde'], ['caracaaa', 'amo', 'kit', 'kat'], ['kit', 'kat', 'rosa', 'primeira', 'vez', 'q', 'vejo', 'gostosin'], ['queria', 'tanto', 'ovo', 'kit', 'kat', '40', 'reais', 'sacanagem'], ['taynarafariad', 'inclusive', 'costa', 'kit', 'kat', 't√°', '180', 'ü§©'], ['liguei', 'farm√°cia', 'comprei', 'dois', 'antial√©rgicos', 'dois', 'neosoros', 'tr√™s', 'kit', 'kat', 'f√°cil', 'ser', 'viciado'], ['vei', 'acabei', 'ver', 'mlk', 'reels', 'botando', 'kit', 'kat', 'prancha', 'skate', 'ai', 'sabe', 'vai', 'foder', 'moral', 'certeza', 'estadunidense'], ['thaidiota', 'horansmiles', 'apagaram'], ['ate', 'onde', 'vc', 'iria', 'eleeu', 'daria', 'peda√ßo', 'kit', 'katüòî', 'httpstcorg6d5o49px'], ['eujojocy', 'thalitacamila2', 'cenastvd', 'kit', 'kat', 'diz', 'tudo', 'bem', 'amar', 'dois', 'hehehe', 'ü§£ü§£ü§£ü§£'], ['tetenc555', 'kit', 'kat', 'estragouta', 'branco', 'causa', 'fungo', 'ü§¢'], ['kitkatoff', 'faz', 'sentido', 'pessoa', 'quer', 'intera√ß√£o', 'desconhecido', 'tranque', 'conta'], ['comprei', 'brigadeiro', 'comi', 'kit', 'kat', 'jujuba', 'batomm', 'agora', 'rango', 'boladoüòãüòã'], ['mainha', 'n', 'trouxer', 'kit', 'kat', 'vou', 'ficar', 'triste'], ['letmeadoyouu', 'kit', 'kat', 'morango', 'bis', 'caixa', 'azul'], ['kit', 'kat', 'perfeito'], ['pico', 'pandemia', 'levar', 'idoso', 'pra', 'banco', 'lotado', 'fazer', 'prova', 'vida'], ['m√£e', 'trouxe', 'kit', 'kat', 'pra', 'mim', 'ü•∞', 'amo', 'mulher'], ['kit', 'kat', 'bom', 'mdss'], ['conquistar', 'bocabolo', 'chocolatesorvete', 'kinder', 'ovo', 'milho', 'verde', 'julguemchocolate', 'suflair', 'kit', 'katsuco', 'maracuj√°', 'refri', 'pepsifruta', 'melancia', 'mel√£o', 'carne', 'picanhabatata', 'doce', 'frita√°gua', 'fria', 'kkkkk', 'slapizza', 'calabresa', 'httpstcoyyhs0wyr1p'], ['whwss', 'quiser', 'paulo', 'fa√ßo', 'kkkkke', 'uns', 'trem', 'cima', 'tipo', 'mampm', 'kit', 'kat', 'etc'], ['alpino', 'melhor', 'chocolate', 'sempre', 'kit', 'kat', 'tbb'], ['tk97mr', 'kit', 'kat', 'caramelo'], ['miichellst', 'olha', 'bom', 'kit', 'kat', 'superior', 'nao'], ['marcoosilva10', 'kit', 'kat', 'melhor', 'chocolate', 'jeito', '√±'], ['tava', 'olhando', 'card√°pio', 'doceira', 'caramelo', 'azul', 'queria', 'ovo', 'kit', 'kat', 'deve', 'ser', 'auge', 'bom'], ['foda', 'q', 'q', 'esperar', '630', 'pra', 'ir', 'comprar', 'bis', 'kit', 'kat', 'üòï'], ['guifps', 'aluno', 'novo', 'poeta', 'httpstcoptvjqytrlf'], ['kitkatoff', 'horansmiles', 'moletom'], ['oooo', 'bis', 'querido', 'obriga√ß√£o', 'nenhuma', 'ser', 'melhor', 'kit', 'kat'], ['money', 'dava', 'ovo', 'kit', 'kat', 'pra', 'katacho', 'combina'], ['quero', 'pacot√£o', 'cheetos', 'kit', 'kat', 'nadaaa'], ['kit', 'kat', 'perfeito', 'pow', 'ü•∞'], ['flapjack', 'mt', 'bom', 'kkkkkkkkkkk'], ['gravaram', 'cenas', 'kit', 'kat', 'm√£o', 'pro', 'mv'], ['to', 'aqui', 'comendo', 'kit', 'kat', 'nao', 'consigo', 'esconder', 'kit', 'kero', 'üòù'], ['comecei', 'kit', 'kat', 'branco', 'recomendo'], ['patyths2', 'rifa', 'maravilhosa', 'cesta', 'chocolateüç´üòãüê∞n√£o', 'vai', 'ficar', 'dessa', 'n√©', '35', 'itens', 'qualidade', 'nutella', 'ferrer‚Ä¶'], ['dei', 'geral', 'casa', 'janelas', 'abertas', 'pra', 'entrar', 'sol', 'vento', 'almo√ßo', 'pronto', 'vou', 'creme', 'cabelo', 'pintar', 'unhas', 'falei', 'm√£e', 'telefone', 'vinho', 'geladeira', 'fandangus', '4', 'kit', 'katpaentreospovos', 'ü•∞ü•∞ü•∞'], ['lembro', 'listando', 'motivos', 'entrar', 'coltec', 'coloquei', 'grande', 'quantidade', 'livros', 'bibliotecaplot', 'twitt', 'nunca', 'cheguei', 'fazer', 'carteirinha', 'biblioteca', 'httpstcoytffxylb5u'], ['t√¥', 'feliz', 'hoje', 'comprei', 'ovos', 'p√°scoa', 'ü•∞ü•∞', 'digo', 'assim', 'porque', 'ainda', 'vai', 'ter', 'outro', 't√¥', 'pensando', 'vai', 'ser', 'üòÜ', 'kit', 'kat', 'sempre', 'lei', '‚ù§', 'httpstcooayqbe0ohk'], ['aceitasse', 'encomendas', 'p√°scoa', 'ovo', 'colher', 'goomerpequeno', '20', 'm√©dio', '25grande', '35', 'recheios', 'brigadeiro', 'leite', 'ninho', 'coco', 'ovomaltineadicionais', 'kit', 'kat', 'bombom', 'pa√ßoca', '√≥reo'], ['louieplacex', 'zainscsy', 'kit', 'kat', 'cobi√ßada'], ['rollingstonebr', 's√©rie', 'brilliant', 'live', 'adventures', 'davidbowie', 'chega', 'fim', 'ciclo', 'dispon√≠vel', 'dia', '2', 'abril', 'cd', 'vinil', 'enc‚Ä¶'], ['apaga', 'amor', 'deus', 'academias', 'estao', 'fechadas', 'choro', 'todo', 'dia', 'comendo', 'kit', 'kat', 'httpstcomkt9m8y5gw'], ['bis', 'extra', 'melhor', 'kit', 'kat', 'vcs', 'pronto', 'pra', 'patrocina', 'lacta'], ['5', 'reais', 'kit', 'kat', 'hospital'], ['kit', 'kat', 'dark', 'simplesmente', 'melhores', 'chocolate', 'q', 'existe'], ['horansmiles', 'kitkatoff', 'participa', 'pra', 'mim', 'amgharry', 'styles'], ['q', 'parar', 'comer', 'kit', 'kat', 'q'], ['andr√©', 'chamou', 'conto', 'ganza', 'kit', 'kat', 'ahahahahahah'], ['comendo', 'kit', 'kat', 'comprei', '2', 'reais'], ['7daysana', 'sim', 'espi√£', 'vibes'], ['ruangabrieltyf2', 'diz', 'quero', 'kit', 'kat', 'obgd'], ['amizade', 'igual', 'grace', 'and', 'frankie', 'velhice', 'morro', 'feliz'], ['doida', 'a√ßa√≠', 'kit', 'kat', 'pra√ßa'], ['sinto', '60', 'ser', 'composto', 'a√ß√∫car', 'ap√≥s', 'comer', 'brigadeiro', 'ninho', 'peda√ßos', 'kit', 'kat'], ['japa', 'mina', 'kit', 'kat', 'bolo', 'chocolate', 'kkkkkk', 'amoo‚ù§Ô∏èü•∞üë≠'], ['rubenteimas', 'lembro', 'vagamente', '1', 'hist√≥ria', 'kit', 'kat'], ['mudei', 'tudo', 'partir', 'hj', 'kit', 'kat', 'fodase', 'httpstcovfa3l2wp6g'], ['vantelov3', 'metade', 'branco', 'metade', 'preto', 'kit', 'kat'], ['vou', 'encomendar', 'ovo', 'colher', 'p', 'comer', 'p√°scoa', 'pq', 'n', 'vai', 'ser', 'vai', 'presentear', 'ovo', 'colher', 'kit', 'kat', 'amo'], ['agr', 'recebi', '50', 'centavos', 'continuarem', 'consigo', 'comprar', 'kit', 'kat', 'httpstcodcq3apvceb'], ['raine', 'deu', 'caixa', 'kit', 'kat', 'fiquei', 'feliz', 'hein', 'pqpüòó'], ['pois', 'queria', 'comprar', 'coisas', 'kit', 'kat', 'promo√ß√£o'], ['ganhei', 'kit', 'kat', 't√¥', 'c√©u', 'httpstcoyfpv0dlnpl'], ['rogeriolubk', 'amea√ßa', 'comunismo', 'exerce', 'papel', 'homem', 'saco', 'adultos', 'capacidade', 'cognitiva', 'reduzida'], ['alantdp', 'comer', 'kit', 'kat', 'üòÇ'], ['kitkatoff', 'acho', 'invasivo', 'üò©üò©üò©üò©'], ['kit', 'kat', 'favorito', 'msm', 'base'], ['anv', 'cai', 'quarta', 'a√ßa√≠', 'ngm', 'mandar', 'a√ßa√≠', 'cheio', 'nutella', 'kit', 'kat', 'vo', 'ficar', 'putassa'], ['queria', 'kit', 'kat', 'diferente', 't√£o', 'comendo'], ['bucado', 'ovo', 'kit', 'kat', 'pra', 'fazer', 'to', 'comendo', 'kit', 'katvo', 'ter', 'compra', 'maisüò≠'], ['irm√£o', 'comeu', 'kit', 'kat', 'inferno', 'barra', 'chocolate', 'inteira', 'pra', 'comeu', 'kitkat', 'q', 'comprei', 'pra', 'mim', 'l√°', 'comeu', 'simplesmente', 'l√°', 'comeu', 'melhor', 'vacil√£o', 'dormir', 'olho', 'aberto', 'hoje', 'vou', 'mete', 'tap√£o', 'nesse', 'ot√°riohttpstco9knpn9oncq'], ['kit', 'kat', 'morango', 'odeio', 'ü§¢ü§Æ'], ['fome', 'pq', 'comi', 'pera', 'kit', 'kat'], ['trouxe', 'nutella', 'bready', 'kit', 'kat', 'morango', 'pra', 'mim', 't√¥', 'mto', 'mimada', 'pena', 'consigo', 'sentir', 'gosto', 'üòÇüòÇ'], ['k3nmavlog', 'so', 'uns', 'kit', 'kat', 'madrugada', 'vc', 'ja', 'comeu'], ['ta√ßa', 'kit', 'kat', 'pastel', 'mania', 'üíîüò¢'], ['vontade', 'comer', 'kit', 'kat', 'httpstcoewgsgpupg7'], ['glaucus121', 'make', 'sense', 'pessoa', 'marca', 'vira', 'conversa', 'duas', 'sabe', 'a√≠', 't√£o', 'falando', 'algo', 'pessoal', 'ali', 'pregui√ßa', 'ir', 'pra', 'dm', 'sei'], ['bebel1912', 'maria', 'come', 'tudo', 'inclusive', 'kit', 'kat', 'adora', 'ü§£ü§£ü§£ü§£ü§£'], ['mtshow95', 'gosta', 'n√©', 'preto', 'kit', 'kat', 'rs'], ['kitkatoff', 'extremamente', 'necessario'], ['drama', 'bergsthem', 'comprou', 'kit', 'kat', 'pra', 'mandar', 'pros', 'cliente', 'comeu', 'tudo'], ['ganhei', '100', 'reias', 'ontem', 'atividades', 'fiz', 'vou', 'comprar', 'kit', 'kat', 'fone'], ['louieplacex', 'perfeita', 'kit', 'kat'], ['lolaescreva', 'gente', 'vamos', 'espalhar', 'tag', 'gravidezfor√ßada√©tortura', 'grave', 'pl5434', 'quer', 'ressuscitar', 'bolsaestupro', 'mulhermen‚Ä¶'], ['leuzxn', 'happyyouare', 'bis', 'barra', 'melhor', 'q', 'kit', 'kat'], ['acabei', 'comprar', '1', 'fondue', 'nao', 'bastante', 'vou', 'enfiar', '2', 'kit', 'kat', 'nele', 'chegar', 'chocolatra', 'normal', 'talvez', 'hora', 'interven√ß√£o', 'corpo', 'vai', 'pipocar', 'espinhas'], ['kitkatoff', 'ser', 'chato', 'coisa', 'meio', 'incoveniente', 'invasivo', 'problema'], ['comprei', 'kit', 'kat', 'bom', 'pode', 'fazer', 'pr√≥prias', 'vontades'], ['lonelys0ul', 'ovo', 'colher', 'ninho', 'ninho', 'kit', 'kat', 'deliciosas', 'caixinhas', 'bombons', 'recheados', 'sortidos', 'httpstcoy6ub9g‚Ä¶'], ['kit', 'kat', 'indo', 'queimar', 'inferno', 'q', 'delicia', 'cena'], ['dfporto', 'seguintepau', 'cu', 'dessa', 'mat√©ria', 'moleque', 'tendo', 'subir', '√°rvore', 'pra', 'poder', 'ter', 'aulapau', 'cu', 'dessa', 'realidade', 'doente‚Ä¶'], ['thalesvictorsan', 't√°', 'tudo', 'caro', 'outra', 'abril', 't√°', 'a√≠', 'gente', 'contenta', 'barra', 'chocolate', 'kit', 'kat', 'aqui', 'comprar', 'concerteza', 'irei', 'ganhar', 'üòÑ'], ['vontade', 'comer', 'kit', 'kat', 'ü•¥'], ['t√°', 'cara', 'legal', 'ningu√©m', 'liga', 'vai', 'comer', 'kit', 'kat']]\n"
     ]
    }
   ],
   "source": [
    "#Coloca todos os tweets da base de teste em uma lista e realiza a limpeza e a retirada dos stopwords \n",
    "test.loc[:,'Teste'] = test.loc[:,'Teste'].astype(str)\n",
    "teste_limpo = []\n",
    "for txt in test['Teste'].tolist():\n",
    "    txt = cleanup(txt)\n",
    "    teste_limpo.append(txt)\n",
    "    teste_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in teste_limpo]\n",
    "div_teste = []\n",
    "for txt in teste_limpo:\n",
    "    txt = txt.split()\n",
    "    div_teste.append(txt)\n",
    "print(div_teste)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando a separa√ß√£o das palavras em listas e calculando suas frequ√™ncias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets muito relevantes\n",
    "mrel_palavras= []\n",
    "for txt in tr_mrel_div:\n",
    "    for wrd in txt:\n",
    "        mrel_palavras.append(wrd )\n",
    "mrel_palavras_serie = pd.Series(mrel_palavras)\n",
    "#mrel_palavras_serie \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets relevantes\n",
    "rel_palavras= []\n",
    "for txt in tr_rel_div:\n",
    "    for wrd in txt:\n",
    "        rel_palavras.append(wrd)\n",
    "rel_palavras_serie = pd.Series(rel_palavras)\n",
    "#rel_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets neutros\n",
    "neut_palavras= []\n",
    "for txt in tr_neut_div:\n",
    "    for wrd in txt:\n",
    "        neut_palavras.append(wrd)\n",
    "neut_palavras_serie = pd.Series(neut_palavras)\n",
    "#neut_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets irrelevantes\n",
    "irrel_palavras= []\n",
    "for txt in tr_irrel_div:\n",
    "    for wrd in txt:\n",
    "        irrel_palavras.append(wrd)\n",
    "irrel_palavras_serie = pd.Series(irrel_palavras)\n",
    "#irrel_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets muito irrelevantes\n",
    "mirrel_palavras= []\n",
    "for txt in tr_mirrel_div:\n",
    "    for wrd in txt:\n",
    "        mirrel_palavras.append(wrd)\n",
    "mirrel_palavras_serie = pd.Series(mirrel_palavras)\n",
    "#mtirrel_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets muito relevantes: \n",
      " kat           6\n",
      "kit           6\n",
      "bom           2\n",
      "vamos         1\n",
      "jvlaruccia    1\n",
      "fodase        1\n",
      "comendo       1\n",
      "ovo           1\n",
      "dms           1\n",
      "branco        1\n",
      "hm            1\n",
      "acho          1\n",
      "belo          1\n",
      "d             1\n",
      "qria          1\n",
      "alpino        1\n",
      "mar3azinha    1\n",
      "agorinhaa     1\n",
      "chocolate     1\n",
      "perfo         1\n",
      "sorvete       1\n",
      "alvxaro       1\n",
      "eh            1\n",
      "sinceros      1\n",
      "prefiro       1\n",
      "ser           1\n",
      "mto           1\n",
      "gostoso       1\n",
      "nenhum        1\n",
      "dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kat           0.150\n",
      "kit           0.150\n",
      "bom           0.050\n",
      "vamos         0.025\n",
      "jvlaruccia    0.025\n",
      "fodase        0.025\n",
      "comendo       0.025\n",
      "ovo           0.025\n",
      "dms           0.025\n",
      "branco        0.025\n",
      "hm            0.025\n",
      "acho          0.025\n",
      "belo          0.025\n",
      "d             0.025\n",
      "qria          0.025\n",
      "alpino        0.025\n",
      "mar3azinha    0.025\n",
      "agorinhaa     0.025\n",
      "chocolate     0.025\n",
      "perfo         0.025\n",
      "sorvete       0.025\n",
      "alvxaro       0.025\n",
      "eh            0.025\n",
      "sinceros      0.025\n",
      "prefiro       0.025\n",
      "ser           0.025\n",
      "mto           0.025\n",
      "gostoso       0.025\n",
      "nenhum        0.025\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Contagem das frequencias das palavras para Muito relevante:\n",
    "\n",
    "# Frequ√™ncia absoluta\n",
    "freq_abs_mrel = mrel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets muito relevantes: \\n\", freq_abs_mrel)\n",
    "\n",
    "# Frequ√™ncia relativa\n",
    "freq_rela_mrel = mrel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_mrel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets relevantes: \n",
      " kit         52\n",
      "kat         52\n",
      "lim√£o        8\n",
      "melhor       7\n",
      "favorito     6\n",
      "            ..\n",
      "demais       1\n",
      "bfrcarou     1\n",
      "mt           1\n",
      "bolo         1\n",
      "descobri     1\n",
      "Length: 213, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kit         0.133333\n",
      "kat         0.133333\n",
      "lim√£o       0.020513\n",
      "melhor      0.017949\n",
      "favorito    0.015385\n",
      "              ...   \n",
      "demais      0.002564\n",
      "bfrcarou    0.002564\n",
      "mt          0.002564\n",
      "bolo        0.002564\n",
      "descobri    0.002564\n",
      "Length: 213, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das frequencias das palavras para Relevante:\n",
    "\n",
    "# Frequ√™ncia absoluta\n",
    "freq_abs_rel = rel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets relevantes: \\n\", freq_abs_rel)\n",
    "\n",
    "\n",
    "#Frequ√™ncia relativa\n",
    "freq_rela_rel = rel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets neutros: \n",
      " kat             38\n",
      "kit             38\n",
      "pra             10\n",
      "vou              7\n",
      "comer            6\n",
      "                ..\n",
      "ngm              1\n",
      "diz              1\n",
      "üôÜüíì               1\n",
      "pois             1\n",
      "thaliaraujo7     1\n",
      "Length: 225, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kat             0.106443\n",
      "kit             0.106443\n",
      "pra             0.028011\n",
      "vou             0.019608\n",
      "comer           0.016807\n",
      "                  ...   \n",
      "ngm             0.002801\n",
      "diz             0.002801\n",
      "üôÜüíì              0.002801\n",
      "pois            0.002801\n",
      "thaliaraujo7    0.002801\n",
      "Length: 225, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das frequencias das palavras para Neutro:\n",
    "\n",
    "# Frequ√™ncia absoluta\n",
    "freq_abs_neut = neut_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets neutros: \\n\", freq_abs_neut)\n",
    "\n",
    "# Frequ√™ncia relativa\n",
    "freq_rela_neut = neut_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_neut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets irrelevantes: \n",
      " kit          44\n",
      "kat          43\n",
      "q             7\n",
      "pra           7\n",
      "comi          6\n",
      "             ..\n",
      "come          1\n",
      "√∫nicas        1\n",
      "dinheiro      1\n",
      "noah          1\n",
      "comprando     1\n",
      "Length: 338, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kit          0.083176\n",
      "kat          0.081285\n",
      "q            0.013233\n",
      "pra          0.013233\n",
      "comi         0.011342\n",
      "               ...   \n",
      "come         0.001890\n",
      "√∫nicas       0.001890\n",
      "dinheiro     0.001890\n",
      "noah         0.001890\n",
      "comprando    0.001890\n",
      "Length: 338, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das frequencias das palavras para Irrelevante:\n",
    "\n",
    "# Frequ√™ncia absoluta\n",
    "freq_abs_irrel = irrel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets irrelevantes: \\n\", freq_abs_irrel)\n",
    "\n",
    "# Frequ√™ncia relativa \n",
    "freq_rela_irrel = irrel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets muito irrelevantes: \n",
      " kit                   95\n",
      "kat                   90\n",
      "pra                   27\n",
      "ovo                   20\n",
      "kitkatoff             16\n",
      "                      ..\n",
      "podemme                1\n",
      "consigam               1\n",
      "subir                  1\n",
      "httpstcofwzgayvdlw     1\n",
      "nate                   1\n",
      "Length: 1046, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kit                   0.054472\n",
      "kat                   0.051606\n",
      "pra                   0.015482\n",
      "ovo                   0.011468\n",
      "kitkatoff             0.009174\n",
      "                        ...   \n",
      "podemme               0.000573\n",
      "consigam              0.000573\n",
      "subir                 0.000573\n",
      "httpstcofwzgayvdlw    0.000573\n",
      "nate                  0.000573\n",
      "Length: 1046, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Contagem das frequencias das palavras para Irrelevante:\n",
    "\n",
    "# Frequ√™ncia absoluta\n",
    "freq_abs_mirrel = mirrel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets muito irrelevantes: \\n\", freq_abs_mirrel)\n",
    "\n",
    "# Frequ√™ncia relativa \n",
    "freq_rela_mirrel = mirrel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_mirrel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desse modo, a probabilidade de um tweet ser relevante ou n√£o ser√° baseado em um compara√ß√£o deste tweet com todas as palavras de nossa base de dados. Isto ser√° feito com um lista de todas as palavras dos tweets que obtivemos, excluindo as repetidas, que ser√£o consideradas como um item de s√©rie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kit          0.076797\n",
       "kat          0.074837\n",
       "pra          0.015686\n",
       "ovo          0.009804\n",
       "chocolate    0.007843\n",
       "               ...   \n",
       "passe        0.000327\n",
       "bolinha      0.000327\n",
       "consigam     0.000327\n",
       "podemme      0.000327\n",
       "pular        0.000327\n",
       "Length: 1474, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cria uma lista com todas as palavras classificadas\n",
    "\n",
    "total = tr_mrel_div + tr_rel_div + tr_neut_div + tr_irrel_div + tr_mirrel_div\n",
    "rel_total= []\n",
    "for txt in total:\n",
    "    for wrd in txt:\n",
    "        rel_total.append(wrd)\n",
    "total_rel_serie = pd.Series(rel_total)\n",
    "relativo_total = total_rel_serie.value_counts(True)\n",
    "relativo_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aumentar a precis√£o e acur√°cia do classificador, decidimos em implementar a suaviza√ß√£o de Laplace, que elimina as probabilidades de valor zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 4, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 1, 4, 3, 1, 3, 1, 3, 4, 3, 3, 1, 4, 3, 3, 3, 3, 1, 3, 3, 3, 1, 1, 3, 1, 4, 1, 1, 3, 3, 1, 1, 3, 3, 3, 4, 3, 3, 3, 1, 3, 4, 1, 1, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 4, 1, 1, 1, 3, 1, 3, 1, 3, 1, 3, 3, 1, 3, 3, 1, 1, 4, 4, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 4, 3, 3, 3, 3, 3, 4, 3, 1, 3, 4, 1, 4, 1, 1, 3, 3, 1, 3, 1, 1, 3, 1, 3, 1, 4, 3, 4, 3, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 4, 3, 1, 3, 3, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 3, 3, 3, 3, 1, 3, 4, 1, 1, 1, 1, 1, 3, 4, 1, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "resp = []\n",
    " \n",
    "mrel_prob=len(freq_abs_mrel)/len(relativo_total)\n",
    "rel_prob=len(freq_abs_rel)/len(relativo_total)\n",
    "neut_prob=len(freq_abs_neut)/len(relativo_total)\n",
    "irrel_prob=len(freq_abs_irrel)/len(relativo_total)\n",
    "mirrel_prob=len(freq_abs_mirrel)/len(relativo_total)\n",
    "for i in range(len(div_teste)):\n",
    "    mrel_prob_txt=[]\n",
    "    rel_prob_txt=[]\n",
    "    neut_prob_txt=[]\n",
    "    irrel_prob_txt=[]\n",
    "    mirrel_prob_txt=[]\n",
    "    for wrd in div_teste[i]:\n",
    "        mrel_prob = 1\n",
    "        rel_prob = 1\n",
    "        neut_prob = 1\n",
    "        irrel_prob = 1\n",
    "        mirrel_prob = 1\n",
    "        #print('\\npalavra: ',palavra)\n",
    "        mrel_prob *= 1/(len(freq_abs_mrel)+len(relativo_total))\n",
    "        rel_prob *= 1/(len(freq_abs_rel)+len(relativo_total))\n",
    "        neut_prob *= 1/(len(freq_abs_neut)+len(relativo_total))\n",
    "        irrel_prob *= 1/(len(freq_abs_irrel)+len(relativo_total))\n",
    "        mirrel_prob *=1/(len(freq_abs_mirrel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_mrel:\n",
    "            mrel_prob += (freq_abs_mrel[wrd ])/(len(freq_abs_mrel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_rel:\n",
    "            rel_prob += (freq_abs_rel[wrd])/(len(freq_abs_rel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_neut:\n",
    "            neut_prob += (freq_abs_neut[wrd ])/(len(freq_abs_neut)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_irrel:\n",
    "            irrel_prob += (freq_abs_irrel[wrd ])/(len(freq_abs_irrel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_mirrel:\n",
    "            mirrel_prob += (freq_abs_mirrel[wrd ])/(len(freq_abs_mirrel)+len(relativo_total))\n",
    " \n",
    "        mrel_prob_txt.append(mrel_prob)\n",
    "        rel_prob_txt.append(rel_prob)\n",
    "        neut_prob_txt.append(neut_prob)\n",
    "        irrel_prob_txt.append(irrel_prob)\n",
    "        mirrel_prob_txt.append(mirrel_prob)\n",
    "        #print('1: ', probFrasedado1)\n",
    "        #print('0: ', probFrasedado0)\n",
    "    if np.prod(mrel_prob_txt)*mrel_prob > np.prod(mirrel_prob_txt)*mirrel_prob:\n",
    "        resp.append(4)\n",
    "    elif np.prod(rel_prob_txt)*rel_prob > np.prod(irrel_prob_txt)*irrel_prob:\n",
    "        resp.append(3)\n",
    "    #elif np.prod(neut_prob_txt)*neut_prob == np.prod(neut_prob_txt)*neut_prob:\n",
    "        #resp.append(2)\n",
    "    elif np.prod(irrel_prob_txt)*irrel_prob > np.prod(rel_prob_txt)*rel_prob:\n",
    "        resp.append(1)\n",
    "    elif np.prod(mirrel_prob_txt)*mirrel_prob > np.prod(mrel_prob_txt)*mrel_prob:\n",
    "        resp.append(0)\n",
    "    else:\n",
    "        resp.append(2)\n",
    "        \n",
    " \n",
    "#print(res)\n",
    "test['Resultado'] = resp\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 4, 3, 3, 1, 3, 3, 1, 1, 3, 3, 3, 1, 4, 3, 1, 3, 1, 3, 4, 3, 3, 1, 4, 3, 3, 3, 3, 1, 3, 3, 3, 1, 1, 3, 1, 4, 1, 1, 3, 3, 1, 1, 3, 3, 3, 4, 3, 3, 3, 1, 3, 4, 1, 1, 3, 3, 1, 3, 1, 3, 3, 1, 1, 3, 4, 1, 1, 1, 3, 1, 3, 1, 3, 1, 3, 3, 1, 3, 3, 1, 1, 4, 4, 3, 3, 3, 1, 1, 3, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 4, 3, 3, 3, 3, 3, 4, 3, 1, 3, 4, 1, 4, 1, 1, 3, 3, 1, 3, 1, 1, 3, 1, 3, 1, 4, 3, 4, 3, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 4, 3, 1, 3, 3, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 3, 3, 3, 3, 1, 3, 4, 1, 1, 1, 1, 1, 3, 4, 1, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "test['Resultado'] = resp\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>class</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Resultado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queria dar de presente pra minha irm√£ o kit ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@123luigig @lilyandgia kit kat √© mt bom</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tudo que eu precisava neste exato momento era:...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kit kat eu te amo esse tu√≠te √© pra vc</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>kit kat indo queimar no inferno, q delicia de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>rt @df_porto: seguinte:\\n\\npau no cu dessa mat...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>@thalesvictorsan t√° tudo caro e outra abril t√°...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>vontade de comer um kit kat ü•¥</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>t√° cara legal, ningu√©m liga se voc√™ vai comer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  class  Unnamed: 2  \\\n",
       "0    queria dar de presente pra minha irm√£ o kit ka...      1         NaN   \n",
       "1              @123luigig @lilyandgia kit kat √© mt bom      4         NaN   \n",
       "2    kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§      4         NaN   \n",
       "3    tudo que eu precisava neste exato momento era:...      4         NaN   \n",
       "4                kit kat eu te amo esse tu√≠te √© pra vc      4         NaN   \n",
       "..                                                 ...    ...         ...   \n",
       "172  kit kat indo queimar no inferno, q delicia de ...      0         NaN   \n",
       "173  rt @df_porto: seguinte:\\n\\npau no cu dessa mat...      0         NaN   \n",
       "174  @thalesvictorsan t√° tudo caro e outra abril t√°...      0         NaN   \n",
       "175                      vontade de comer um kit kat ü•¥      4         NaN   \n",
       "176  t√° cara legal, ningu√©m liga se voc√™ vai comer ...      0         NaN   \n",
       "\n",
       "     Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Resultado  \n",
       "0           NaN         NaN         NaN         NaN          3  \n",
       "1           NaN         NaN         NaN         NaN          3  \n",
       "2           NaN         NaN         NaN         NaN          3  \n",
       "3           NaN         NaN         NaN         NaN          3  \n",
       "4           NaN         NaN         NaN         NaN          3  \n",
       "..          ...         ...         ...         ...        ...  \n",
       "172         NaN         NaN         NaN         NaN          3  \n",
       "173         NaN         NaN         NaN         NaN          4  \n",
       "174         NaN         NaN         NaN         NaN          1  \n",
       "175         NaN         NaN         NaN         NaN          3  \n",
       "176         NaN         NaN         NaN         NaN          3  \n",
       "\n",
       "[177 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Resultado'] = resp\n",
    "test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    " \n",
    " A performance do classificador ser√° verificada atrav√©s da an√°lise de verdadeiros positivos, verdadeiros negativos, falsos positivos e falsos negativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resultado</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resultado   1   3   4\n",
       "class                \n",
       "0          17  20  18\n",
       "1           4  10   0\n",
       "2          18   5   0\n",
       "3          16  18   1\n",
       "4          10  40   0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['class'],test['Resultado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resultado</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.327273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resultado         1         3         4\n",
       "class                                  \n",
       "0          0.309091  0.363636  0.327273\n",
       "1          0.285714  0.714286  0.000000\n",
       "2          0.782609  0.217391  0.000000\n",
       "3          0.457143  0.514286  0.028571\n",
       "4          0.200000  0.800000  0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['class'],test['Resultado'],normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de acertos:  22\n",
      "Porcentagem de acertos: 12.429%\n"
     ]
    }
   ],
   "source": [
    "lista_classificacao = test['class'].tolist()\n",
    "lista_resultado = test['Resultado'].tolist()\n",
    " \n",
    "test_mrelevante = test.loc[test['class'] == 4,:]\n",
    "test_relevante = test.loc[test['class'] == 3,:]\n",
    "test_neutro = test.loc[test['class'] == 2,:]\n",
    "test_irrelevante = test.loc[test['class'] == 1,:]\n",
    "test_mirrelevante = test.loc[test['class'] == 0,:]\n",
    "acertos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == lista_resultado[i]:\n",
    "        acertos += 1\n",
    "porcentagem_acertos = acertos/len(lista_classificacao)\n",
    "print(\"N√∫mero de acertos: \", acertos)\n",
    "print(\"Porcentagem de acertos: {0:.3f}%\".format(porcentagem_acertos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de verdadeiros positivos:  18\n",
      "Porcentagem de verdadeiros positivos: 21.176%\n"
     ]
    }
   ],
   "source": [
    "lista_classificacao = test['class'].tolist()\n",
    "lista_resultado  = test['Resultado'].tolist()\n",
    "\n",
    "verdadeiros_positivos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 4 and lista_resultado[i] == 4:\n",
    "        verdadeiros_positivos += 1\n",
    "    elif lista_classificacao[i] == 3 and lista_resultado[i]== 3:\n",
    "        verdadeiros_positivos += 1\n",
    "porcentagem_verdadeiros_positivos = verdadeiros_positivos/(len(test_mrelevante)+len(test_relevante))\n",
    "print(\"N√∫mero de verdadeiros positivos: \", verdadeiros_positivos)\n",
    "print(\"Porcentagem de verdadeiros positivos: {0:.3f}%\".format(porcentagem_verdadeiros_positivos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de falsos positivos:  53\n",
      "Porcentagem de falsos positivos: 76.812%\n"
     ]
    }
   ],
   "source": [
    "falsos_positivos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 0 and lista_resultado[i] == 4:\n",
    "        falsos_positivos += 1\n",
    "    elif lista_classificacao[i] == 0 and lista_resultado[i]== 3:\n",
    "        falsos_positivos += 1\n",
    "    elif lista_classificacao[i] == 1 and lista_resultado[i]== 4:\n",
    "        falsos_positivos += 1\n",
    "    elif lista_classificacao[i] == 1 and lista_resultado[i]== 3:\n",
    "        falsos_positivos += 1\n",
    "    elif lista_classificacao[i] == 2 and lista_resultado[i]== 4:\n",
    "        falsos_positivos += 1\n",
    "    elif lista_classificacao[i] == 2 and lista_resultado[i]== 3:\n",
    "        falsos_positivos += 1\n",
    "porcentagem_falsos_positivos = falsos_positivos/(len(test_mirrelevante)+ len(test_irrelevante))\n",
    "print(\"N√∫mero de falsos positivos: \", falsos_positivos)\n",
    "print(\"Porcentagem de falsos positivos: {0:.3f}%\".format(porcentagem_falsos_positivos*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de verdadeiros negativos:  4\n",
      "Porcentagem de verdadeiros negativos: 5.797%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 0 and lista_resultado[i] == 0:\n",
    "        verdadeiros_negativos += 1\n",
    "    elif lista_classificacao[i] == 1 and lista_resultado[i]== 1:\n",
    "        verdadeiros_negativos += 1\n",
    "porcentagem_verdadeiros_negativos = verdadeiros_negativos/(len(test_irrelevante) + len(test_mirrelevante))\n",
    "print(\"N√∫mero de verdadeiros negativos: \", verdadeiros_negativos)\n",
    "print(\"Porcentagem de verdadeiros negativos: {0:.3f}%\".format(porcentagem_verdadeiros_negativos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de falsos negativos:  44\n",
      "Porcentagem de falsos negativos: 51.765%\n"
     ]
    }
   ],
   "source": [
    "falsos_negativos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 4 and lista_resultado[i] == 0:\n",
    "        falsos_negativos += 1\n",
    "    elif lista_classificacao[i] == 4 and lista_resultado[i]== 1:\n",
    "        falsos_negativos += 1\n",
    "    elif lista_classificacao[i] == 3 and lista_resultado[i]== 0:\n",
    "        falsos_negativos += 1\n",
    "    elif lista_classificacao[i] == 3 and lista_resultado[i]== 1:\n",
    "        falsos_negativos += 1\n",
    "    elif lista_classificacao[i] == 2 and lista_resultado[i]== 0:\n",
    "        falsos_negativos += 1\n",
    "    elif lista_classificacao[i] == 2 and lista_resultado[i]== 1:\n",
    "        falsos_negativos += 1\n",
    "porcentagem_falsos_negativos = falsos_negativos/(len(test_relevante) + len(test_mrelevante))\n",
    "print(\"N√∫mero de falsos negativos: \", falsos_negativos)\n",
    "print(\"Porcentagem de falsos negativos: {0:.3f}%\".format(porcentagem_falsos_negativos*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resultado</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.096045</td>\n",
       "      <td>0.112994</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.310734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.028249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090395</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.005650</td>\n",
       "      <td>0.197740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056497</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.367232</td>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.107345</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resultado         1         3         4       All\n",
       "class                                            \n",
       "0          0.096045  0.112994  0.101695  0.310734\n",
       "1          0.022599  0.056497  0.000000  0.079096\n",
       "2          0.101695  0.028249  0.000000  0.129944\n",
       "3          0.090395  0.101695  0.005650  0.197740\n",
       "4          0.056497  0.225989  0.000000  0.282486\n",
       "All        0.367232  0.525424  0.107345  1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadro = pd.crosstab(test['class'], test['Resultado'], margins = True, normalize = True)\n",
    "quadro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N√£o foi poss√≠vel adicionar as classifica√ß√µes Muito irrelevante e Neutro na tabela de conclus√£o por erro no c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador n√£o resultou em boa performance pois a porcentagem de verdadeiros positivos e negativos √© de, respectivamente, 21.176% e 5.797%. Esses resultados demonstram uma alta taxa de erros na classifica√ß√£o produzida pelo classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIferentes cen√°rios:\n",
    "\n",
    "- Pode ser usado para classificar textos ou artigos universit√°rios\n",
    "- Uso em pesquisa de mercado, para prever popularidade de algum produto\n",
    "- Classifica√ß√£o de e-mails, para separar mensagens spam e relevantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhorias:\n",
    "- Ampliar o quantidade de stopwords para obter uma filtragem melhor de palavras que n√£o inferem sentimento no tweet.\n",
    "- Aplicar uma fun√ß√£o que detecte sarcasmo nas mensagens, melhorando a efic√°cia da classifica√ß√£o.\n",
    "- Buscar erros no c√≥digo, que levaram aos baixos valores de verdadeiros positivos e negativos.\n",
    "- Rever a classifica√ß√£o realizada no excel antes do desenvolvimento do classificador.\n",
    "- Simplifica√ß√£o do c√≥digo para compact√°-lo e demandar menos poder de computa√ß√£o.\n",
    "- Aumentar a quantidade de tweets em geral para obten√ß√£o de mais amostras e treinar de forma mais ampla o classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
