{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Lucas Franco Florentino\n",
    "\n",
    "Nome: Lucas Kang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo kit kat.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "filename = 'kit kat.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@biaturci bia tmb √© did√°tica!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 kit kat por 10 pila na americanas, vou logo ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e se eu trocar meu nick pra: kit kat...\\nalgue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@pivetabeca o pre√ßo q eh uma barra de kit kat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qria um ovo d chocolate da alpino ou da kit ka...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  class\n",
       "0                    @biaturci bia tmb √© did√°tica!!!      0\n",
       "1  6 kit kat por 10 pila na americanas, vou logo ...      2\n",
       "2  e se eu trocar meu nick pra: kit kat...\\nalgue...      0\n",
       "3  @pivetabeca o pre√ßo q eh uma barra de kit kat ...      1\n",
       "4  qria um ovo d chocolate da alpino ou da kit ka...      4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>class</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queria dar de presente pra minha irm√£ o kit ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@123luigig @lilyandgia kit kat √© mt bom</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tudo que eu precisava neste exato momento era:...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kit kat eu te amo esse tu√≠te √© pra vc</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  class  Unnamed: 2  \\\n",
       "0  queria dar de presente pra minha irm√£ o kit ka...      1         NaN   \n",
       "1            @123luigig @lilyandgia kit kat √© mt bom      4         NaN   \n",
       "2  kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§      4         NaN   \n",
       "3  tudo que eu precisava neste exato momento era:...      4         NaN   \n",
       "4              kit kat eu te amo esse tu√≠te √© pra vc      4         NaN   \n",
       "\n",
       "   Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  \n",
       "0         NaN         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN         NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "def cleanup(text):\n",
    "    punctuation = '[/\\@!-.:?;\\n\"\"‚Äú‚Äù,_]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    texto_limpo= re.sub(pattern, '', text)\n",
    "    return  texto_limpo\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('portuguese')\n",
    "stop_list = [\"de\", \"√©\", \"√°\", \"√†\", \"ao\", \"a\", \"o\", \"√©\", \"rt\", '\"', \"‚Äú\", \"'\", \",\", \"(\", \")\", \"$\", \"%\", \"*\", \"&\", \"+\", \"=\"]\n",
    "stop.extend(stop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-789d7b17280e>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-31-789d7b17280e>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    train.class.cat.categories = ['Muito Irrelevante', 'Irrelevante', 'Neutro', 'Relevante',' Muito Relevante']\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "treino_mrel = train.loc[train['class'] == 4,:]\n",
    "treino_rel = train.loc[train['class'] == 3,:]\n",
    "treino_neut = train.loc[train['class'] == 2,:]\n",
    "treino_irrel = train.loc[train['class'] == 1,:]\n",
    "treino_mirrel = train.loc[train['class'] == 0,:]\n",
    "\n",
    "teste_mrel= test.loc[train['class'] == 4,:]\n",
    "teste_rel = test.loc[train['class'] == 3,:]\n",
    "teste_neut = test.loc[train['class'] == 2,:]\n",
    "teste_irrel = test.loc[train['class'] == 1,:]\n",
    "teste_mirrel = test.loc[train['class'] == 0,:]\n",
    "\n",
    "train['class'] = train['class'].astype('category')\n",
    "test['class'] = test['class'].astype('category')\n",
    "\n",
    "train.class.cat.categories = ['Muito Irrelevante', 'Irrelevante', 'Neutro', 'Relevante',' Muito Relevante']\n",
    "test.class.cat.categories = ['Muito Irrelevante', 'Irrelevante', 'Neutro', 'Relevante',' Muito Relevante']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-695579089b16>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_mrel['Treinamento'] = treino_mrel['Treinamento'].astype(str)\n",
      "<ipython-input-32-695579089b16>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_rel['Treinamento'] = treino_rel['Treinamento'].astype(str)\n",
      "<ipython-input-32-695579089b16>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_neut['Treinamento'] = treino_neut['Treinamento'].astype(str)\n",
      "<ipython-input-32-695579089b16>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_irrel['Treinamento'] = treino_irrel['Treinamento'].astype(str)\n",
      "<ipython-input-32-695579089b16>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  treino_mirrel['Treinamento'] = treino_mirrel['Treinamento'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "treino_mrel['Treinamento'] = treino_mrel['Treinamento'].astype(str)\n",
    "treino_rel['Treinamento'] = treino_rel['Treinamento'].astype(str)\n",
    "treino_neut['Treinamento'] = treino_neut['Treinamento'].astype(str)\n",
    "treino_irrel['Treinamento'] = treino_irrel['Treinamento'].astype(str)\n",
    "treino_mirrel['Treinamento'] = treino_mirrel['Treinamento'].astype(str)\n",
    " \n",
    "#Passando a base de treinamento para uma lista\n",
    "lista_tr_mrel= treino_mrel['Treinamento'].tolist()\n",
    "lista_tr_rel= treino_rel['Treinamento'].tolist()\n",
    "lista_tr_neut= treino_neut['Treinamento'].tolist()\n",
    "lista_tr_irrel= treino_irrel['Treinamento'].tolist()\n",
    "lista_tr_mirrel= treino_mirrel['Treinamento'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mrel_limpo = []\n",
    "for txt in lista_tr_mrel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_mrel_limpo.append(txt)\n",
    " \n",
    "tr_mrel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_mrel_limpo]\n",
    "    \n",
    "tr_mrel_split = []\n",
    "for txt in tr_mrel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_mrel_split.append(txt)\n",
    " \n",
    "#Aplicando a limpeza de stopwords na lista de treinamento relevante\n",
    "tr_rel_limpo = []\n",
    "for txt in lista_tr_rel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_rel_limpo.append(txt)\n",
    " \n",
    "tr_rel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_rel_limpo]\n",
    "    \n",
    "tr_rel_split = []\n",
    "for txt in tr_rel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_rel_split.append(txt)\n",
    " \n",
    "#Aplicando a limpeza de stopwords na lista de treinamento neutro\n",
    "tr_neut_limpo = []\n",
    "for txt in lista_tr_neut:\n",
    "    txt = cleanup(txt)\n",
    "    tr_neut_limpo.append(txt)\n",
    " \n",
    "tr_neut_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_neut_limpo]\n",
    "    \n",
    "tr_neut_split = []\n",
    "for txt in tr_neut_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_neut_split.append(txt)\n",
    " \n",
    "#Aplicando a limpeza de stopwords na lista de treinamento irrelevante\n",
    "tr_irrel_limpo = []\n",
    "for txt in lista_tr_irrel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_irrel_limpo.append(txt)\n",
    " \n",
    "tr_irrel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_irrel_limpo]\n",
    "    \n",
    "tr_irrel_split = []\n",
    "for txt in tr_irrel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_irrel_split.append(txt)\n",
    " \n",
    "#Aplicando a limpeza de stopwords na lista de treinamento muito irrelevante\n",
    "tr_mirrel_limpo = []\n",
    "for txt in lista_tr_mirrel:\n",
    "    txt = cleanup(txt)\n",
    "    tr_mirrel_limpo.append(txt)\n",
    " \n",
    "tr_mirrel_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in tr_mirrel_limpo]\n",
    "    \n",
    "tr_mirrel_split = []\n",
    "for txt in tr_mirrel_limpo:\n",
    "    txt= txt.split()\n",
    "    tr_mirrel_split.append(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['queria', 'dar', 'presente', 'pra', 'irm√£', 'kit', 'kat', 'parceria', 'now', 'united', '99', 'reais', 'chocolate', 'ü§°', 'cara', 'tentando', 'cancelar', 'compra', 'email', 'ver', 'valor', '135', 'estalecas', 'frete', 'sabendo', 'deixaram', 'claro', 'antes', 'compra', 'httpstcoeverznihri'], ['123luigig', 'lilyandgia', 'kit', 'kat', 'mt', 'bom'], ['kit', 'kat', 'morango', 'lim√£o', 'tudo', 'pra', 'mim', 'ü•∫ü§§'], ['tudo', 'precisava', 'neste', 'exato', 'momento', 'eraum', 'bolo', 'recheio', 'abacaxium', 'bolo', 'churrosum', 'bolo', 'algum', 'chantily', 'gostoso', 'cremoso', 'cima', 'recheio', 'chocolate', 'doce', 'leiteuma', 'torta', 'morangos', 'kit', 'kat', 'qlqr', 'fazia', 'feliz'], ['kit', 'kat', 'amo', 'tu√≠te', 'pra', 'vc'], ['crystaltriste', '3', 'anos', 'info', 'sabe', 'hackear', 'links', 'achar', 'links'], ['liviabarroos', 'fala', 'escuto', 'grito', 'causa', 'kit', 'kat'], ['professora', 'disse', 'ligar', 'camera', 'ganha', 'kit', 'kat', 'httpstcoa2ywkrlzx7'], ['esperei', 'tanto', 'p√°scoa', 'finalmente', 't√°', 'chegando', 'vou', 'ter', 'dinheiro', 'pra', 'comprar', 'kit', 'kat', 'kkkkkkkk'], ['fabymello', 'cheia', 'vontade', 'a√ßa√≠', 'trufado', 'kit', 'kat', 'üò¢'], ['clovestill', 'gente', 'perai', 'httpstcob1aczg6ysh'], ['kitkatoff', 'falsos', 'coltecanos'], ['karolindav', 'fala', 'patroa', 'f√°cil', 'vc', 'dar', 'pode', 'ser', 'kit', 'kat', 'msm', 'p√¥', 'kkkkkk'], ['kit', 'kat', 'horr√≠vel'], ['kitkatoff', 'assim', 'invasivo', 'chamo', 'desconhecidos', 'amor', 'vida', 'nesse', 'site'], ['kit', 'kat', 'httpstcofdoueh24nu'], ['souzzaav', 'aaah', 'vou', 'sim', 't√¥', 'quase', 'indo', 'la', 'comprar', 'kit', 'kat'], ['mesmos', 'criadores', 'pink', 'money', 'vcsdiscordia', 'money', 'httpstcod5kceu24wp'], ['kitkatwbitch', 'ne', 'kit', 'kat'], ['crystaltriste', 'bem', 'ead', 'sei', 'pode', 'invadir', 'links'], ['ainda', 'kit', 'kat', 'ksksksksksksksk'], ['cara', 'compra', 'maconha', 'enqnt', 'podia', 'comprar', 'kit', 'kat', 'kkkkkkkkkkkkkkkk'], ['pensando', 'pago', '80', 'ovo', 'p√°scoa', 'pego', 'dinheiro', 'compro', 'chocolates', 'aleat√≥rios', 'chuva', 'kinder', 'bueno', 'kit', 'kat', 'laka', 'oreo', 'ü§î'], ['mylauram', 't√¥', 'vendo', 'aqui', 'fant√°stico', 'rob√¥s', 'coreia', 'copiando', 'voz', 'artista', 'morto', '20', 'anos', 'pensando', 'quantidade‚Ä¶'], ['avalia√ß√£o', 'aqui', 'comi', 'kit', 'kat', 'gold', 'eh', 'mto', 'ruim', 'parece', 'doce', 'furreba', 'p', 'comer', 'pauzinho', 'so', 'deppis', 'nunca', 'üëçüèª'], ['tristeza', 'cacha√ßa', 'kit', 'kat'], ['queria', 'ganhar', 'm√∫sculo', 'comendo', 'kit', 'kat', 'barras', 'chocolate', 'pedir'], ['le101010', 'aposto', 'dummie', 'dessa', 'prova', 'formou', 'hospedagem', 'cefet'], ['devorkatrina', 'amaryssage', 'kit', 'kat', 'rostinho', 'detonado', 'deixa', 'fazer', 'draminha'], ['queria', 'comer', 'uns', '10', 'kit', 'kat', 'vez'], ['henriquealcini', 't√°', 'sobrevivendo', 'ü§∑üèª\\u200d‚ôÄÔ∏è'], ['markidsp', 'loiolatinha', 'kitkatoff', 'blz', 'mestre'], ['gente', 'responde', 'pffse', 'fizer', 'ovo', 'p√°scoa', 'recheado', 'tp', 'ninho', 'kit', 'kat', 'vcs', 'compram', 'm√£o'], ['caixa', 'kit', 'kat', 'p√°scoa', 'deixaria', 'feliz', 'vida', 'üòç'], ['vontade', 'mt', 'grande', 'comer', 'kit', 'kat', 'kkkkkkk', 'üò≠'], ['nunossauro', 'deres', 'kit', 'kat', 'posso', 'pensar', 'nisso'], ['ovo', 'colher', 'ninho', 'ninho', 'kit', 'kat', 'deliciosas', 'caixinhas', 'bombons', 'recheados', 'sortidos', 'httpstcoy6ub9g5xyx'], ['anivers√°rio', 'guardei', 'kit', 'kat', 'caixinha', 'guarda', 'roupa', 'ai', 'mecher', 'ma', 'caixinha', 'tava', 'la', 'kit', 'kat', 'kkkkkmkkkmmm'], ['ovo', 'p√°scoa', 'kit', 'kat', 'super', 'fininho', 'pequeno', 'comprem', 'deve', 'valer', 'pena', 'pre√ßo', 'pago', 'quero', 'comprar', 'link'], ['pra', 'comer', 'kit', 'kat', 'lambuzar', 'todo'], ['biaturci', 'presidente', 'falou', 'discordar'], ['pai', 'q', 'falou', 'q', 't√°', 'vendo', 'q', 't√¥', 'triste', 'lockdown', 'lembra', 'amava', 'ovo', 'p√°scoa', 'qnd', 'pequena', 'ent', 'comprou', 'kit', 'kat', 'pra', 'mim', 's√©rio', 'q', 'pfto', 'q', 'eh'], ['fiz', 'brigadeiro', 'kit', 'kat', 'ficou', 'mara', 'httpstco9jj5yvqrqo'], ['quer', 'chamar', 'aten√ß√£o', 'compra', 'ovo', 'p√°scoa', 'kit', 'kat', 'p', 'mim'], ['nunca', 'vontade', 'comer', 'doce', 'ai', 'qnd', 'come√ßo', 'treinar', 'd√°', 'vontade', 'comer', 'naked', 'cake', 'c', 'recheio', 'brigadeiro', 'leite', 'ninho', 'milkshake', 'baunilha', 'bobs', 'kinder', 'bueno', 'kit', 'kat', 'aql', 'sorvete', 'hersheys', 'cookiesn', 'cream', 'kibonmeu', 'deus'], ['andreezagomes', 'amooo', 'kit', 'kat', 'kkkkkk'], ['lactabis', 'kit', 'kat', 'ganha', 'lavada', 'bis'], ['mexer', 'mochila', 'achei', 'kit', 'kat', 'fechado', 'tr√™s', 'mil', 'anos', 'atr√°sirei', 'comer', 'd√∫vidas'], ['barbizinea', 'quer', 'chamar', 'aten√ß√£o', 'compra', 'ovo', 'p√°scoa', 'kit', 'kat', 'p', 'mim'], ['jvlaruccia', 'kit', 'kat', 'favorito', 'c'], ['glaucus121', 'invasivo', 'chato', 'talvez'], ['ainda', 'comprou', '6', 'kit', 'kat', 'pra', 'mim', 'ü§©üò¢'], ['matheusamores', 'yanzerass', 'ai', 'liga', 'iphone', 'aparece', 'android', '44', 'kit', 'kat', 'n', 'sabe', 'pq', 'kkkkk'], ['promo√ß√£o', '6', 'kit', 'kat', '10', 'tudo', 'vida', 'queria', 'agora'], ['qr', 'ta√ßa', 'sorvete', 'ovomaltine', 'kit', 'kat', 'chocolate', 'xtudo', 'pizza', 'üò£üò´üò´üò´üò´', 'pedir'], ['ano', 'decidi', 'queria', 'comer', 'ovo', 'p√°scoa', 'caseiro', 'dificuldade', 'achar', 'oreonutellakit', 'kat'], ['marhelo', 'certeza', 'vc', 'casou', 'comigo', 'n√©'], ['kitkats2', 'equitorboquilh', 'felizmente', 'comprometida', 'pra', 'n', 'perder', 'embalo', 'passo', 'pra', 'amiga', 'solteira', 'mengwao', 'üòçüòçüôèüèª'], ['algumas', 'quest√µes', 'aqmds', 'mlk', 'nick', 'merda', 'fodase', 'verme', 'gosteivc', 'n', 'patrickinho', 'apenas', 'queria', 'nick', 'proprio', 'q', 'n', 'nomepq', 'kit', 'kat', 'lol', 'mono', 'katarina', 'amo', 'chocolate', 'acho', 'q', 'ja', 'responde', 'pergunta'], ['ricardopinto20', 'andr√©', 'chamou', 'conto', 'ganza', 'kit', 'kat', 'ahahahahahah'], ['acai', 'nutella', 'morango', 'kit', 'kat', 'erro', 'httpstcorxhjpzp6dk'], ['louieplacex', 'amo', 'tava', 'precisando', 'umas', 'realidades', 'cara', 'sei', 'kit', 'kat'], ['kit', 'kat', 'gold', 'rapaziada', 'comprem', 'ofensa', 'chocolates', 'podre', 'demais'], ['zadoratavares', 'nada', 'melhor', 'receber', 'visita', 'moz√£o', 'trabalho', 'ainda', 'ganhar', 'kit', 'kat', 'nubscampos10', 'menina', 'linda', 'demais‚Ä¶'], ['queria', 'kit', 'kat', 'agora'], ['bfrkarlos', 'ugosantos33', 'rafaela', 'kit', 'kat', 'melhor'], ['vou', 'comer', 'kit', 'kat', 'agora', 'pra', 'fechar', 'noite'], ['descri√ß√£o', 'cesta', 'mini', 'nutella', '140g1', 'barra', 'laka1', 'barra', 'garato', '1', 'caixa', 'ferrero', 'rocher', '100g2', 'pacotes', 'mampm', '45g2', 'barra', 'kit', 'kat2', 'pacote', 'amendoim', 'bibs', '1', 'ovo', '350g', 'ouro', 'branco', '1', 'pacote', 'skittles', '1', 'bebida', 'alpino', '1', 'caixa', 'bis', 'continua'], ['vida', 'mentira', 'pq', 'sempre', 'falei', 'kit', 'vs', 'kat', 'httpstcoqhwd7pmotm'], ['sunsetjoyner', 'sacha', 'httpstcox8uprirmyk'], ['fellipec', 'peguei', 'logo', 'come√ßo', 'pestequando', 'algu√©m', 'fala', 'pegou', 'tomou', 'nada', 'grave', 'digo', 'peguei', 'tomei', '2', 'copos', 'coca', 'cola', '1', 'kit', 'kat', 'dia', 'tb', 'nada', 'grave'], ['uns', '10', 'kit', 'kat', 'alguns', 'finis', 'caixinha', 'bis', 'pra', 'curar', 'tristeza', 'tpmüòû'], ['harrylipstyles', 'compra', 'kit', 'kat', 'barato', 'kinder', 'ovo', 'vc', 'pode', 'comer', 'comum', 'qualquer', '√©poca', 'ano', '2', 'kit', 'kat', 'pre√ßo', '1', 'kinder', 'ovo'], ['caroline', 'sabia', 'sobre', 'vampirismo', 'tanto', 'perguntava', 'qdo', 'viu', 'face', 'assustou', 'logo', 'ali', 'hipnotizada', 'tirar', 'medo', 'assustar', 'face', 'estupro', 'podemos', 'dizer', 'todos', 'estupradores', 'assim', 'kit', 'kat'], ['gusbarcelos', 'sejehomi', 'kitkatbrasil', 'al√¥', 'kitkatbrasil', 'apoie', 'hist√≥ria', 'desse', 'casal', 'lindo', 'ama', 'kit', 'kat', 'namorada', 'amamos', 'vou', 'roubar', 'momento', 'casal'], ['coisas', 'compraria', 'facilmente', 'pasta', 'cremosa', 'kit', 'kat', '21', 'kg'], ['dessa', 'vez', 'fiz', 'rematricula', 'okay'], ['preciso', 'emagrecer', 't√¥', 'gordameu', 'caf√©', 'manh√£', 'hoje', 'doritos', 'kit', 'kat', '√°gua', 'pra', 'dar', 'equilibrada'], ['p√°scoa', 'membros', 'poderiam', 'vestir', 'dan√ßar', 'vers√£o', 'turn', 'it', 'up', 'vestidos', 'coelhos', 'enquanto', 'comiam', 'kit', 'kat', 'partyup'], ['kavmartins', 'josuealm', 't√°', 'gra√ßa', 'sabe', 'gosto', 'kit', 'kat', 'üôÑ', 't√°', 'fazendo', 'porque', 'ultimamente', 'anda', 'rebelde'], ['caracaaa', 'amo', 'kit', 'kat'], ['kit', 'kat', 'rosa', 'primeira', 'vez', 'q', 'vejo', 'gostosin'], ['queria', 'tanto', 'ovo', 'kit', 'kat', '40', 'reais', 'sacanagem'], ['taynarafariad', 'inclusive', 'costa', 'kit', 'kat', 't√°', '180', 'ü§©'], ['liguei', 'farm√°cia', 'comprei', 'dois', 'antial√©rgicos', 'dois', 'neosoros', 'tr√™s', 'kit', 'kat', 'f√°cil', 'ser', 'viciado'], ['vei', 'acabei', 'ver', 'mlk', 'reels', 'botando', 'kit', 'kat', 'prancha', 'skate', 'ai', 'sabe', 'vai', 'foder', 'moral', 'certeza', 'estadunidense'], ['thaidiota', 'horansmiles', 'apagaram'], ['ate', 'onde', 'vc', 'iria', 'eleeu', 'daria', 'peda√ßo', 'kit', 'katüòî', 'httpstcorg6d5o49px'], ['eujojocy', 'thalitacamila2', 'cenastvd', 'kit', 'kat', 'diz', 'tudo', 'bem', 'amar', 'dois', 'hehehe', 'ü§£ü§£ü§£ü§£'], ['tetenc555', 'kit', 'kat', 'estragouta', 'branco', 'causa', 'fungo', 'ü§¢'], ['kitkatoff', 'faz', 'sentido', 'pessoa', 'quer', 'intera√ß√£o', 'desconhecido', 'tranque', 'conta'], ['comprei', 'brigadeiro', 'comi', 'kit', 'kat', 'jujuba', 'batomm', 'agora', 'rango', 'boladoüòãüòã'], ['mainha', 'n', 'trouxer', 'kit', 'kat', 'vou', 'ficar', 'triste'], ['letmeadoyouu', 'kit', 'kat', 'morango', 'bis', 'caixa', 'azul'], ['kit', 'kat', 'perfeito'], ['pico', 'pandemia', 'levar', 'idoso', 'pra', 'banco', 'lotado', 'fazer', 'prova', 'vida'], ['m√£e', 'trouxe', 'kit', 'kat', 'pra', 'mim', 'ü•∞', 'amo', 'mulher'], ['kit', 'kat', 'bom', 'mdss'], ['conquistar', 'bocabolo', 'chocolatesorvete', 'kinder', 'ovo', 'milho', 'verde', 'julguemchocolate', 'suflair', 'kit', 'katsuco', 'maracuj√°', 'refri', 'pepsifruta', 'melancia', 'mel√£o', 'carne', 'picanhabatata', 'doce', 'frita√°gua', 'fria', 'kkkkk', 'slapizza', 'calabresa', 'httpstcoyyhs0wyr1p'], ['whwss', 'quiser', 'paulo', 'fa√ßo', 'kkkkke', 'uns', 'trem', 'cima', 'tipo', 'mampm', 'kit', 'kat', 'etc'], ['alpino', 'melhor', 'chocolate', 'sempre', 'kit', 'kat', 'tbb'], ['tk97mr', 'kit', 'kat', 'caramelo'], ['miichellst', 'olha', 'bom', 'kit', 'kat', 'superior', 'nao'], ['marcoosilva10', 'kit', 'kat', 'melhor', 'chocolate', 'jeito', '√±'], ['tava', 'olhando', 'card√°pio', 'doceira', 'caramelo', 'azul', 'queria', 'ovo', 'kit', 'kat', 'deve', 'ser', 'auge', 'bom'], ['foda', 'q', 'q', 'esperar', '630', 'pra', 'ir', 'comprar', 'bis', 'kit', 'kat', 'üòï'], ['guifps', 'aluno', 'novo', 'poeta', 'httpstcoptvjqytrlf'], ['kitkatoff', 'horansmiles', 'moletom'], ['oooo', 'bis', 'querido', 'obriga√ß√£o', 'nenhuma', 'ser', 'melhor', 'kit', 'kat'], ['money', 'dava', 'ovo', 'kit', 'kat', 'pra', 'katacho', 'combina'], ['quero', 'pacot√£o', 'cheetos', 'kit', 'kat', 'nadaaa'], ['kit', 'kat', 'perfeito', 'pow', 'ü•∞'], ['flapjack', 'mt', 'bom', 'kkkkkkkkkkk'], ['gravaram', 'cenas', 'kit', 'kat', 'm√£o', 'pro', 'mv'], ['to', 'aqui', 'comendo', 'kit', 'kat', 'nao', 'consigo', 'esconder', 'kit', 'kero', 'üòù'], ['comecei', 'kit', 'kat', 'branco', 'recomendo'], ['patyths2', 'rifa', 'maravilhosa', 'cesta', 'chocolateüç´üòãüê∞n√£o', 'vai', 'ficar', 'dessa', 'n√©', '35', 'itens', 'qualidade', 'nutella', 'ferrer‚Ä¶'], ['dei', 'geral', 'casa', 'janelas', 'abertas', 'pra', 'entrar', 'sol', 'vento', 'almo√ßo', 'pronto', 'vou', 'creme', 'cabelo', 'pintar', 'unhas', 'falei', 'm√£e', 'telefone', 'vinho', 'geladeira', 'fandangus', '4', 'kit', 'katpaentreospovos', 'ü•∞ü•∞ü•∞'], ['lembro', 'listando', 'motivos', 'entrar', 'coltec', 'coloquei', 'grande', 'quantidade', 'livros', 'bibliotecaplot', 'twitt', 'nunca', 'cheguei', 'fazer', 'carteirinha', 'biblioteca', 'httpstcoytffxylb5u'], ['t√¥', 'feliz', 'hoje', 'comprei', 'ovos', 'p√°scoa', 'ü•∞ü•∞', 'digo', 'assim', 'porque', 'ainda', 'vai', 'ter', 'outro', 't√¥', 'pensando', 'vai', 'ser', 'üòÜ', 'kit', 'kat', 'sempre', 'lei', '‚ù§', 'httpstcooayqbe0ohk'], ['aceitasse', 'encomendas', 'p√°scoa', 'ovo', 'colher', 'goomerpequeno', '20', 'm√©dio', '25grande', '35', 'recheios', 'brigadeiro', 'leite', 'ninho', 'coco', 'ovomaltineadicionais', 'kit', 'kat', 'bombom', 'pa√ßoca', '√≥reo'], ['louieplacex', 'zainscsy', 'kit', 'kat', 'cobi√ßada'], ['rollingstonebr', 's√©rie', 'brilliant', 'live', 'adventures', 'davidbowie', 'chega', 'fim', 'ciclo', 'dispon√≠vel', 'dia', '2', 'abril', 'cd', 'vinil', 'enc‚Ä¶'], ['apaga', 'amor', 'deus', 'academias', 'estao', 'fechadas', 'choro', 'todo', 'dia', 'comendo', 'kit', 'kat', 'httpstcomkt9m8y5gw'], ['bis', 'extra', 'melhor', 'kit', 'kat', 'vcs', 'pronto', 'pra', 'patrocina', 'lacta'], ['5', 'reais', 'kit', 'kat', 'hospital'], ['kit', 'kat', 'dark', 'simplesmente', 'melhores', 'chocolate', 'q', 'existe'], ['horansmiles', 'kitkatoff', 'participa', 'pra', 'mim', 'amgharry', 'styles'], ['q', 'parar', 'comer', 'kit', 'kat', 'q'], ['andr√©', 'chamou', 'conto', 'ganza', 'kit', 'kat', 'ahahahahahah'], ['comendo', 'kit', 'kat', 'comprei', '2', 'reais'], ['7daysana', 'sim', 'espi√£', 'vibes'], ['ruangabrieltyf2', 'diz', 'quero', 'kit', 'kat', 'obgd'], ['amizade', 'igual', 'grace', 'and', 'frankie', 'velhice', 'morro', 'feliz'], ['doida', 'a√ßa√≠', 'kit', 'kat', 'pra√ßa'], ['sinto', '60', 'ser', 'composto', 'a√ß√∫car', 'ap√≥s', 'comer', 'brigadeiro', 'ninho', 'peda√ßos', 'kit', 'kat'], ['japa', 'mina', 'kit', 'kat', 'bolo', 'chocolate', 'kkkkkk', 'amoo‚ù§Ô∏èü•∞üë≠'], ['rubenteimas', 'lembro', 'vagamente', '1', 'hist√≥ria', 'kit', 'kat'], ['mudei', 'tudo', 'partir', 'hj', 'kit', 'kat', 'fodase', 'httpstcovfa3l2wp6g'], ['vantelov3', 'metade', 'branco', 'metade', 'preto', 'kit', 'kat'], ['vou', 'encomendar', 'ovo', 'colher', 'p', 'comer', 'p√°scoa', 'pq', 'n', 'vai', 'ser', 'vai', 'presentear', 'ovo', 'colher', 'kit', 'kat', 'amo'], ['agr', 'recebi', '50', 'centavos', 'continuarem', 'consigo', 'comprar', 'kit', 'kat', 'httpstcodcq3apvceb'], ['raine', 'deu', 'caixa', 'kit', 'kat', 'fiquei', 'feliz', 'hein', 'pqpüòó'], ['pois', 'queria', 'comprar', 'coisas', 'kit', 'kat', 'promo√ß√£o'], ['ganhei', 'kit', 'kat', 't√¥', 'c√©u', 'httpstcoyfpv0dlnpl'], ['rogeriolubk', 'amea√ßa', 'comunismo', 'exerce', 'papel', 'homem', 'saco', 'adultos', 'capacidade', 'cognitiva', 'reduzida'], ['alantdp', 'comer', 'kit', 'kat', 'üòÇ'], ['kitkatoff', 'acho', 'invasivo', 'üò©üò©üò©üò©'], ['kit', 'kat', 'favorito', 'msm', 'base'], ['anv', 'cai', 'quarta', 'a√ßa√≠', 'ngm', 'mandar', 'a√ßa√≠', 'cheio', 'nutella', 'kit', 'kat', 'vo', 'ficar', 'putassa'], ['queria', 'kit', 'kat', 'diferente', 't√£o', 'comendo'], ['bucado', 'ovo', 'kit', 'kat', 'pra', 'fazer', 'to', 'comendo', 'kit', 'katvo', 'ter', 'compra', 'maisüò≠'], ['irm√£o', 'comeu', 'kit', 'kat', 'inferno', 'barra', 'chocolate', 'inteira', 'pra', 'comeu', 'kitkat', 'q', 'comprei', 'pra', 'mim', 'l√°', 'comeu', 'simplesmente', 'l√°', 'comeu', 'melhor', 'vacil√£o', 'dormir', 'olho', 'aberto', 'hoje', 'vou', 'mete', 'tap√£o', 'nesse', 'ot√°riohttpstco9knpn9oncq'], ['kit', 'kat', 'morango', 'odeio', 'ü§¢ü§Æ'], ['fome', 'pq', 'comi', 'pera', 'kit', 'kat'], ['trouxe', 'nutella', 'bready', 'kit', 'kat', 'morango', 'pra', 'mim', 't√¥', 'mto', 'mimada', 'pena', 'consigo', 'sentir', 'gosto', 'üòÇüòÇ'], ['k3nmavlog', 'so', 'uns', 'kit', 'kat', 'madrugada', 'vc', 'ja', 'comeu'], ['ta√ßa', 'kit', 'kat', 'pastel', 'mania', 'üíîüò¢'], ['vontade', 'comer', 'kit', 'kat', 'httpstcoewgsgpupg7'], ['glaucus121', 'make', 'sense', 'pessoa', 'marca', 'vira', 'conversa', 'duas', 'sabe', 'a√≠', 't√£o', 'falando', 'algo', 'pessoal', 'ali', 'pregui√ßa', 'ir', 'pra', 'dm', 'sei'], ['bebel1912', 'maria', 'come', 'tudo', 'inclusive', 'kit', 'kat', 'adora', 'ü§£ü§£ü§£ü§£ü§£'], ['mtshow95', 'gosta', 'n√©', 'preto', 'kit', 'kat', 'rs'], ['kitkatoff', 'extremamente', 'necessario'], ['drama', 'bergsthem', 'comprou', 'kit', 'kat', 'pra', 'mandar', 'pros', 'cliente', 'comeu', 'tudo'], ['ganhei', '100', 'reias', 'ontem', 'atividades', 'fiz', 'vou', 'comprar', 'kit', 'kat', 'fone'], ['louieplacex', 'perfeita', 'kit', 'kat'], ['lolaescreva', 'gente', 'vamos', 'espalhar', 'tag', 'gravidezfor√ßada√©tortura', 'grave', 'pl5434', 'quer', 'ressuscitar', 'bolsaestupro', 'mulhermen‚Ä¶'], ['leuzxn', 'happyyouare', 'bis', 'barra', 'melhor', 'q', 'kit', 'kat'], ['acabei', 'comprar', '1', 'fondue', 'nao', 'bastante', 'vou', 'enfiar', '2', 'kit', 'kat', 'nele', 'chegar', 'chocolatra', 'normal', 'talvez', 'hora', 'interven√ß√£o', 'corpo', 'vai', 'pipocar', 'espinhas'], ['kitkatoff', 'ser', 'chato', 'coisa', 'meio', 'incoveniente', 'invasivo', 'problema'], ['comprei', 'kit', 'kat', 'bom', 'pode', 'fazer', 'pr√≥prias', 'vontades'], ['lonelys0ul', 'ovo', 'colher', 'ninho', 'ninho', 'kit', 'kat', 'deliciosas', 'caixinhas', 'bombons', 'recheados', 'sortidos', 'httpstcoy6ub9g‚Ä¶'], ['kit', 'kat', 'indo', 'queimar', 'inferno', 'q', 'delicia', 'cena'], ['dfporto', 'seguintepau', 'cu', 'dessa', 'mat√©ria', 'moleque', 'tendo', 'subir', '√°rvore', 'pra', 'poder', 'ter', 'aulapau', 'cu', 'dessa', 'realidade', 'doente‚Ä¶'], ['thalesvictorsan', 't√°', 'tudo', 'caro', 'outra', 'abril', 't√°', 'a√≠', 'gente', 'contenta', 'barra', 'chocolate', 'kit', 'kat', 'aqui', 'comprar', 'concerteza', 'irei', 'ganhar', 'üòÑ'], ['vontade', 'comer', 'kit', 'kat', 'ü•¥'], ['t√°', 'cara', 'legal', 'ningu√©m', 'liga', 'vai', 'comer', 'kit', 'kat']]\n"
     ]
    }
   ],
   "source": [
    "test.loc[:,'Teste'] = test.loc[:,'Teste'].astype(str)\n",
    "teste_limpo = []\n",
    "for txt in test['Teste'].tolist():\n",
    "    txt = cleanup(txt)\n",
    "    teste_limpo.append(txt)\n",
    " \n",
    "teste_limpo = [' '.join([w for w in x.lower().split() if w not in stop]) \n",
    "    for x in teste_limpo]\n",
    " \n",
    "split_teste = []\n",
    "for txt in teste_limpo:\n",
    "    txt = txt.split()\n",
    "    split_teste.append(txt)\n",
    "print(split_teste)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           qria\n",
       "1            ovo\n",
       "2              d\n",
       "3      chocolate\n",
       "4         alpino\n",
       "5            kit\n",
       "6            kat\n",
       "7             hm\n",
       "8           acho\n",
       "9          perfo\n",
       "10           dms\n",
       "11       alvxaro\n",
       "12        nenhum\n",
       "13       prefiro\n",
       "14           kit\n",
       "15           kat\n",
       "16    jvlaruccia\n",
       "17           kit\n",
       "18           kat\n",
       "19           bom\n",
       "20        branco\n",
       "21         vamos\n",
       "22           ser\n",
       "23      sinceros\n",
       "24           kit\n",
       "25           kat\n",
       "26       sorvete\n",
       "27       gostoso\n",
       "28           kit\n",
       "29           kat\n",
       "30            eh\n",
       "31           mto\n",
       "32           bom\n",
       "33        fodase\n",
       "34    mar3azinha\n",
       "35       comendo\n",
       "36          belo\n",
       "37           kit\n",
       "38           kat\n",
       "39     agorinhaa\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Contagem da frequencia das palavras dos tweets muito relevantes\n",
    "mrel_palavras= []\n",
    "for txt in tr_mrel_split:\n",
    "    for wrd in txt:\n",
    "        mrel_palavras.append(wrd )\n",
    "mrel_palavras_serie = pd.Series(mrel_palavras)\n",
    "mrel_palavras_serie \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets muito relevantes\n",
    "mrel_palavras= []\n",
    "for txt in tr_mrel_split:\n",
    "    for wrd in txt:\n",
    "        mrel_palavras.append(wrd )\n",
    "mrel_palavras_serie = pd.Series(mrel_palavras)\n",
    "#mrel_palavras_serie \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets relevantes\n",
    "rel_palavras= []\n",
    "for txt in tr_rel_split:\n",
    "    for wrd in txt:\n",
    "        rel_palavras.append(wrd)\n",
    "rel_palavras_serie = pd.Series(rel_palavras)\n",
    "#rel_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets neutros\n",
    "neut_palavras= []\n",
    "for txt in tr_neut_split:\n",
    "    for wrd in txt:\n",
    "        neut_palavras.append(wrd)\n",
    "neut_palavras_serie = pd.Series(neut_palavras)\n",
    "#neut_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets irrelevantes\n",
    "irrel_palavras= []\n",
    "for txt in tr_irrel_split:\n",
    "    for wrd in txt:\n",
    "        irrel_palavras.append(wrd)\n",
    "irrel_palavras_serie = pd.Series(irrel_palavras)\n",
    "#irrel_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contagem da frequencia das palavras dos tweets muito irrelevantes\n",
    "mirrel_palavras= []\n",
    "for txt in tr_mirrel_split:\n",
    "    for wrd in txt:\n",
    "        mirrel_palavras.append(wrd)\n",
    "mirrel_palavras_serie = pd.Series(mirrel_palavras)\n",
    "#mtirrel_palavras_serie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets muito relevantes: \n",
      " kat           6\n",
      "kit           6\n",
      "bom           2\n",
      "ovo           1\n",
      "eh            1\n",
      "gostoso       1\n",
      "alvxaro       1\n",
      "belo          1\n",
      "mto           1\n",
      "vamos         1\n",
      "ser           1\n",
      "sinceros      1\n",
      "prefiro       1\n",
      "d             1\n",
      "dms           1\n",
      "jvlaruccia    1\n",
      "alpino        1\n",
      "branco        1\n",
      "sorvete       1\n",
      "perfo         1\n",
      "agorinhaa     1\n",
      "hm            1\n",
      "acho          1\n",
      "fodase        1\n",
      "mar3azinha    1\n",
      "comendo       1\n",
      "nenhum        1\n",
      "qria          1\n",
      "chocolate     1\n",
      "dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kat           0.150\n",
      "kit           0.150\n",
      "bom           0.050\n",
      "ovo           0.025\n",
      "eh            0.025\n",
      "gostoso       0.025\n",
      "alvxaro       0.025\n",
      "belo          0.025\n",
      "mto           0.025\n",
      "vamos         0.025\n",
      "ser           0.025\n",
      "sinceros      0.025\n",
      "prefiro       0.025\n",
      "d             0.025\n",
      "dms           0.025\n",
      "jvlaruccia    0.025\n",
      "alpino        0.025\n",
      "branco        0.025\n",
      "sorvete       0.025\n",
      "perfo         0.025\n",
      "agorinhaa     0.025\n",
      "hm            0.025\n",
      "acho          0.025\n",
      "fodase        0.025\n",
      "mar3azinha    0.025\n",
      "comendo       0.025\n",
      "nenhum        0.025\n",
      "qria          0.025\n",
      "chocolate     0.025\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Contagem das frequencias absolutas das palavras dos tweets muito relevantes\n",
    "freq_abs_mrel = mrel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets muito relevantes: \\n\", freq_abs_mrel)\n",
    "#Contagem das frequencias relativas das palavras dos tweets muito relevantes\n",
    "freq_rela_mrel = mrel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_mrel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets relevantes: \n",
      " kat          52\n",
      "kit          52\n",
      "lim√£o         8\n",
      "melhor        7\n",
      "favorito      6\n",
      "             ..\n",
      "diamante      1\n",
      "vi            1\n",
      "meio          1\n",
      "pena          1\n",
      "enjoativo     1\n",
      "Length: 213, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kat          0.133333\n",
      "kit          0.133333\n",
      "lim√£o        0.020513\n",
      "melhor       0.017949\n",
      "favorito     0.015385\n",
      "               ...   \n",
      "diamante     0.002564\n",
      "vi           0.002564\n",
      "meio         0.002564\n",
      "pena         0.002564\n",
      "enjoativo    0.002564\n",
      "Length: 213, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Contagem das frequencias absolutas das palavras dos tweets relevantes\n",
    "freq_abs_rel = rel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets relevantes: \\n\", freq_abs_rel)\n",
    "#Contagem das frequencias relativas das palavras dos tweets relevantes\n",
    "freq_rela_rel = rel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets neutros: \n",
      " kat             38\n",
      "kit             38\n",
      "pra             10\n",
      "vou              7\n",
      "comer            6\n",
      "                ..\n",
      "bolo             1\n",
      "üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©         1\n",
      "quente           1\n",
      "urreaslegend     1\n",
      "condi√ß√µes        1\n",
      "Length: 225, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kat             0.106443\n",
      "kit             0.106443\n",
      "pra             0.028011\n",
      "vou             0.019608\n",
      "comer           0.016807\n",
      "                  ...   \n",
      "bolo            0.002801\n",
      "üë©‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë©        0.002801\n",
      "quente          0.002801\n",
      "urreaslegend    0.002801\n",
      "condi√ß√µes       0.002801\n",
      "Length: 225, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Contagem das frequencias absolutas das palavras dos tweets neutros\n",
    "freq_abs_neut = neut_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets neutros: \\n\", freq_abs_neut)\n",
    "#Contagem das frequencias relativas das palavras dos tweets neutros\n",
    "freq_rela_neut = neut_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_neut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets irrelevantes: \n",
      " kit          95\n",
      "kat          90\n",
      "pra          27\n",
      "ovo          20\n",
      "kitkatoff    16\n",
      "             ..\n",
      "nisso         1\n",
      "face          1\n",
      "perto         1\n",
      "prato         1\n",
      "üò¢             1\n",
      "Length: 1046, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kit          0.054472\n",
      "kat          0.051606\n",
      "pra          0.015482\n",
      "ovo          0.011468\n",
      "kitkatoff    0.009174\n",
      "               ...   \n",
      "nisso        0.000573\n",
      "face         0.000573\n",
      "perto        0.000573\n",
      "prato        0.000573\n",
      "üò¢            0.000573\n",
      "Length: 1046, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Contagem das frequencias absolutas das palavras dos tweets irrelevantes\n",
    "freq_abs_irrel = irrel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets irrelevantes: \\n\", freq_abs_irrel)\n",
    "#Contagem das frequencias relativas das palavras dos tweets muito irrelevantes\n",
    "freq_rela_irrel = irrel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequencias absolutas dos tweets muito irrelevantes: \n",
      " kit          95\n",
      "kat          90\n",
      "pra          27\n",
      "ovo          20\n",
      "kitkatoff    16\n",
      "             ..\n",
      "nisso         1\n",
      "face          1\n",
      "perto         1\n",
      "prato         1\n",
      "üò¢             1\n",
      "Length: 1046, dtype: int64\n",
      "\n",
      "Frequencias relativas: \n",
      " kit          0.054472\n",
      "kat          0.051606\n",
      "pra          0.015482\n",
      "ovo          0.011468\n",
      "kitkatoff    0.009174\n",
      "               ...   \n",
      "nisso        0.000573\n",
      "face         0.000573\n",
      "perto        0.000573\n",
      "prato        0.000573\n",
      "üò¢            0.000573\n",
      "Length: 1046, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Contagem das frequencias absolutas das palavras dos tweets muito irrelevantes\n",
    "freq_abs_mirrel = mirrel_palavras_serie.value_counts()\n",
    "print(\"\\nFrequencias absolutas dos tweets muito irrelevantes: \\n\", freq_abs_mirrel)\n",
    "#Contagem das frequencias relativas das palavras dos tweets muito irrelevantes\n",
    "freq_rela_mirrel = mirrel_palavras_serie.value_counts(normalize = True)\n",
    "print(\"\\nFrequencias relativas: \\n\", freq_rela_mirrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kit          0.076797\n",
       "kat          0.074837\n",
       "pra          0.015686\n",
       "ovo          0.009804\n",
       "chocolate    0.007843\n",
       "               ...   \n",
       "mimü•∞         0.000327\n",
       "renovar      0.000327\n",
       "ta√ßa         0.000327\n",
       "perto        0.000327\n",
       "katt√°        0.000327\n",
       "Length: 1474, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = tr_mrel_split + tr_rel_split + tr_neut_split + tr_irrel_split + tr_mirrel_split\n",
    "rel_total= []\n",
    "for txt in total:\n",
    "    for wrd in txt:\n",
    "        rel_total.append(wrd)\n",
    "total_rel_serie = pd.Series(rel_total)\n",
    "relativo_total = total_rel_serie.value_counts(True)\n",
    "relativo_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "resp = []\n",
    " \n",
    "prob4=len(freq_abs_mrel)/len(relativo_total)\n",
    "prob3=len(freq_abs_rel)/len(relativo_total)\n",
    "prob2=len(freq_abs_neut)/len(relativo_total)\n",
    "prob1=len(freq_abs_irrel)/len(relativo_total)\n",
    "prob0=len(freq_abs_mirrel)/len(relativo_total)\n",
    "for i in range(len(split_teste)):\n",
    "    mrel_prob=[]\n",
    "    rel_prob=[]\n",
    "    neut_prob=[]\n",
    "    irrel_prob=[]\n",
    "    mirrel_prob=[]\n",
    "    for wrd in split_teste[i]:\n",
    "        probFrasedado4 = 1\n",
    "        probFrasedado3 = 1\n",
    "        probFrasedado2 = 1\n",
    "        probFrasedado1 = 1\n",
    "        probFrasedado0 = 1\n",
    "        #print('\\npalavra: ',palavra)\n",
    "        probFrasedado4 *= 1/(len(freq_abs_mrel)+len(relativo_total))\n",
    "        probFrasedado3 *= 1/(len(freq_abs_rel)+len(relativo_total))\n",
    "        probFrasedado2 *= 1/(len(freq_abs_neut)+len(relativo_total))\n",
    "        probFrasedado1 *= 1/(len(freq_abs_irrel)+len(relativo_total))\n",
    "        probFrasedado0 *=1/(len(freq_abs_mirrel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_mrel:\n",
    "            probFrasedado4 += (freq_abs_mrel[wrd ])/(len(freq_abs_mrel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_rel:\n",
    "            probFrasedado3 += (freq_abs_rel[wrd])/(len(freq_abs_rel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_neut:\n",
    "            probFrasedado2 += (freq_abs_neut[wrd ])/(len(freq_abs_neut)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_irrel:\n",
    "            probFrasedado1 += (freq_abs_irrel[wrd ])/(len(freq_abs_irrel)+len(relativo_total))\n",
    " \n",
    "        if wrd in freq_abs_mirrel:\n",
    "            probFrasedado0 += (freq_abs_mirrel[wrd ])/(len(freq_abs_mirrel)+len(relativo_total))\n",
    " \n",
    "        mrel_prob.append(probFrasedado4)\n",
    "        rel_prob.append(probFrasedado3)\n",
    "        neut_prob.append(probFrasedado2)\n",
    "        irrel_prob.append(probFrasedado1)\n",
    "        mirrel_prob.append(probFrasedado0)\n",
    "        #print('1: ', probFrasedado1)\n",
    "        #print('0: ', probFrasedado0)\n",
    "    if np.prod(mrel_prob)*prob4 > np.prod(mirrel_prob)*prob0:\n",
    "        resp.append(1)\n",
    "    elif np.prod(rel_prob)*prob3 > np.prod(irrel_prob)*prob1:\n",
    "        resp.append(1)\n",
    "    else:\n",
    "        resp.append(0)\n",
    " \n",
    "#print(res)\n",
    "test['Resolucao'] = resp\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "test['Resolucao'] = resp\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>class</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Resolucao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queria dar de presente pra minha irm√£ o kit ka...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@123luigig @lilyandgia kit kat √© mt bom</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tudo que eu precisava neste exato momento era:...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kit kat eu te amo esse tu√≠te √© pra vc</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>kit kat indo queimar no inferno, q delicia de ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>rt @df_porto: seguinte:\\n\\npau no cu dessa mat...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>@thalesvictorsan t√° tudo caro e outra abril t√°...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>vontade de comer um kit kat ü•¥</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>t√° cara legal, ningu√©m liga se voc√™ vai comer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  class  Unnamed: 2  \\\n",
       "0    queria dar de presente pra minha irm√£ o kit ka...      1         NaN   \n",
       "1              @123luigig @lilyandgia kit kat √© mt bom      4         NaN   \n",
       "2    kit kat de morango e de lim√£o s√£o tudo pra mim ü•∫ü§§      4         NaN   \n",
       "3    tudo que eu precisava neste exato momento era:...      4         NaN   \n",
       "4                kit kat eu te amo esse tu√≠te √© pra vc      4         NaN   \n",
       "..                                                 ...    ...         ...   \n",
       "172  kit kat indo queimar no inferno, q delicia de ...      0         NaN   \n",
       "173  rt @df_porto: seguinte:\\n\\npau no cu dessa mat...      0         NaN   \n",
       "174  @thalesvictorsan t√° tudo caro e outra abril t√°...      0         NaN   \n",
       "175                      vontade de comer um kit kat ü•¥      4         NaN   \n",
       "176  t√° cara legal, ningu√©m liga se voc√™ vai comer ...      0         NaN   \n",
       "\n",
       "     Unnamed: 3  Unnamed: 4  Unnamed: 5  Unnamed: 6  Resolucao  \n",
       "0           NaN         NaN         NaN         NaN          0  \n",
       "1           NaN         NaN         NaN         NaN          0  \n",
       "2           NaN         NaN         NaN         NaN          0  \n",
       "3           NaN         NaN         NaN         NaN          0  \n",
       "4           NaN         NaN         NaN         NaN          0  \n",
       "..          ...         ...         ...         ...        ...  \n",
       "172         NaN         NaN         NaN         NaN          0  \n",
       "173         NaN         NaN         NaN         NaN          0  \n",
       "174         NaN         NaN         NaN         NaN          0  \n",
       "175         NaN         NaN         NaN         NaN          0  \n",
       "176         NaN         NaN         NaN         NaN          0  \n",
       "\n",
       "[177 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Resolucao'] = resp\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resolucao</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resolucao   0   1\n",
       "class            \n",
       "0          44  11\n",
       "1          12   2\n",
       "2          21   2\n",
       "3          28   7\n",
       "4          39  11"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['class'],test['Resolucao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resolucao</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resolucao         0         1\n",
       "class                        \n",
       "0          0.800000  0.200000\n",
       "1          0.857143  0.142857\n",
       "2          0.913043  0.086957\n",
       "3          0.800000  0.200000\n",
       "4          0.780000  0.220000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['class'],test['Resolucao'],normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de acertos:  46\n",
      "Porcentagem de acertos: 25.989%\n"
     ]
    }
   ],
   "source": [
    "lista_classificacao = test['class'].tolist()\n",
    "lista_resolucao = test['Resolucao'].tolist()\n",
    " \n",
    "test_relevante = test.loc[test['class'] == 1,:]\n",
    "test_irrelevante = test.loc[test['class'] == 0,:]\n",
    " \n",
    "acertos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == lista_resolucao[i]:\n",
    "        acertos += 1\n",
    "porcentagem_acertos = acertos/len(lista_classificacao)\n",
    "print(\"N√∫mero de acertos: \", acertos)\n",
    "print(\"Porcentagem de acertos: {0:.3f}%\".format(porcentagem_acertos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de verdadeiros positivos:  2\n",
      "Porcentagem de verdadeiros positivos: 14.286%\n"
     ]
    }
   ],
   "source": [
    "lista_classificacao = test['class'].tolist()\n",
    "lista_resolucao = test['Resolucao'].tolist()\n",
    " \n",
    "verdadeiros_positivos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 1 and lista_resolucao[i] == 1:\n",
    "        verdadeiros_positivos += 1\n",
    "porcentagem_verdadeiros_positivos = verdadeiros_positivos/len(test_relevante)\n",
    "print(\"N√∫mero de verdadeiros positivos: \", verdadeiros_positivos)\n",
    "print(\"Porcentagem de verdadeiros positivos: {0:.3f}%\".format(porcentagem_verdadeiros_positivos*100))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de falsos positivos:  11\n",
      "Porcentagem de falsos positivos: 20.000%\n"
     ]
    }
   ],
   "source": [
    "falsos_positivos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 0 and lista_resolucao[i] == 1:\n",
    "        falsos_positivos += 1\n",
    "porcentagem_falsos_positivos = falsos_positivos/len(test_irrelevante)\n",
    "print(\"N√∫mero de falsos positivos: \", falsos_positivos)\n",
    "print(\"Porcentagem de falsos positivos: {0:.3f}%\".format(porcentagem_falsos_positivos*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de verdadeiros negativos:  44\n",
      "Porcentagem de verdadeiros negativos: 80.000%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 0 and lista_resolucao[i] == 0:\n",
    "        verdadeiros_negativos += 1\n",
    "porcentagem_verdadeiros_negativos = verdadeiros_negativos/len(test_irrelevante)\n",
    "print(\"N√∫mero de verdadeiros negativos: \", verdadeiros_negativos)\n",
    "print(\"Porcentagem de verdadeiros negativos: {0:.3f}%\".format(porcentagem_verdadeiros_negativos*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de falsos negativos:  12\n",
      "Porcentagem de falsos negativos: 85.714%\n"
     ]
    }
   ],
   "source": [
    "falsos_negativos = 0\n",
    "for i in range(len(lista_classificacao)):\n",
    "    if lista_classificacao[i] == 1 and lista_resolucao[i] == 0:\n",
    "        falsos_negativos += 1\n",
    "porcentagem_falsos_negativos = falsos_negativos/len(test_relevante)\n",
    "print(\"N√∫mero de falsos negativos: \", falsos_negativos)\n",
    "print(\"Porcentagem de falsos negativos: {0:.3f}%\".format(porcentagem_falsos_negativos*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "ESCREVA AQUI..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
